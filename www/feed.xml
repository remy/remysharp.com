<?xml version="1.0" encoding="utf-8" ?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/"><channel><title>remy sharp's b:log</title><atom:link href="http://remysharp.com/feed/" rel="self" type="application/rss+xml"></atom:link><link>http://remysharp.com</link><description>About [code] and all that jazz</description><lastBuildDate>Wed, 11 Mar 2015 14:30:00 +0000</lastBuildDate><language>en-US</language><sy:updatePeriod>hourly</sy:updatePeriod><sy:updateFrequency>1</sy:updateFrequency><item><title>Diet</title><guid isPermaLink="false">diet</guid><link>http://remysharp.com/2015/03/11/diet</link><pubDate>Wed, 11 Mar 2015 14:30:00 +0000</pubDate><description><![CDATA[I&#39;ve been asked a few times what&#39;s my diet like, specifically, and I wanted to write it up here so I actually remember in years to come. This is because I&#39;ve gone from 30%+ body fat (obese) to 11.75% (inside athlete categorisation) over 2 years.]]></description><content:encoded><![CDATA[
<p>I&#39;ve been asked a few times what&#39;s my diet like, specifically, and I wanted to write it up here so I actually remember in years to come. This is because I&#39;ve gone from 30%+ body fat (obese) to 11.75% (inside athlete categorisation) over 2 years.</p>
<p><img src="/images/2012-2014.jpg" alt="2012 - 2014"></p>
<h2>Purpose</h2>
<p>The first consideration I had back at the start of 2013 was how do I start and what do I want to achieve?</p>
<p>I&#39;d read a lot around the <a href="http://en.wikipedia.org/wiki/Paleolithic_diet">Palio diet</a> and the <a href="http://en.wikipedia.org/wiki/Slow-Carb_Diet">Slow-Carb diet</a> and a decided that if I was to get outside of the obese categorisation, I needed something simple. I needed to lose weight (body fat) and diet is 80% of the job (20% is the gym).</p>
<p>I decided that I would cut wheat and dairy out of my diet. That&#39;s all (to start off with).</p>
<p>That means no cheese. No sandwiches. No cheese sandwiches either. I can&#39;t say it was easy, and lunch was very hard. Lunchtime became falafel or burrito salad boxes. But there&#39;s no avoiding it, what you ultimately have to do is cook your own food ahead of time.</p>
<p>In addition, by mid-March that year, I also quit drinking for 3 months, long enough that I&#39;m not really bothered about drinking today.</p>
<p>This diet change, combined with the gym (not cardio, just lifting heavy and compound lifts) 3 days a week go me what I needed: down to 25% in 4 months.</p>
<h2>66 days</h2>
<p>You can&#39;t change your habits overnight. It typically takes <a href="http://www.telegraph.co.uk/health/healthnews/5857845/It-takes-66-days-to-form-a-habit.html">two months</a> to create a new habit. For me, that was my change of diet (and knowing what to eat at lunchtime!) and the gym.</p>
<p>It&#39;s hard, there&#39;s no doubt, but for me, it was, and is: worth it.</p>
<p>But to achieve that first hurdle of 2 months, you need to prevent failing.</p>
<h2>Failing</h2>
<p>I&#39;ve written <a href="https://remysharp.com/2014/01/27/cheat">about this before</a>, but here&#39;s the short version: cheat and do everything you can to make it impossible to fail.</p>
<p>Too often have I tried to start something new, only to miss one day of that something, then a week, then I&#39;m procrastinating, then I&#39;m embarrassed and eventually I admit I&#39;ve failed.</p>
<p>In this case, if I miss a day (of the gym or slip up on the diet), then it&#39;s a <em>cheat</em>. I&#39;ll tell myself I&#39;m allowed to, and it&#39;s intentional. If it&#39;s going to be two days of cheating, the <em>it&#39;s all part of the plan</em>.</p>
<p>I plan Saturday as my cheat day. And I go bananas...</p>
<figure><img class="withcredit" src="/images/cheat-day.jpg" title="Cheat day"><figcaption class="credit">And sometimes <a href="https://www.youtube.com/watch?v=VWgwJfbeCeU">I&#39;ll go crazy on the Butterfield diet</a>!</figcaption></figure>

<p>It&#39;s possibly not ideal to go <em>so</em> nuts, and more recently I&#39;ve backed off a bit, but it&#39;s my cheat day, and it keeps me sane and it can be fun too!</p>
<h2>My diet</h2>
<p>Just to be clear: this is not <em>a</em> diet, this is just <em>my</em> diet. This is based on a roughly 1,500-1,700 calories consumed aiming for a carb, protein and fat split of 30%, 50% and 20% respectively (though gym days would tend to be at the high end).</p>
<p>I&#39;ve broken my day into the times that I eat. When I include more than one item, it means that I&#39;ll rotate any of these foods. Where I&#39;ve included links, it&#39;s either to the specific product or recipes.</p>
<p>Note that this is also based on working from an office that only had a fridge, but no heating equipment. And yes, it&#39;s dull. It doesn&#39;t vary that much, but heck, when I was buying the same sandwich 3 times a week from the cornershop it&#39;s like that was variation!</p>
<table>
<thead>
<tr>
<th>When</th>
<th align="center">What</th>
</tr>
</thead>
<tbody>
<tr>
<td>7am / breakfast<br>within 30mins of waking</td>
<td align="center"><a href="http://www.tesco.com/groceries/product/details/?id=283691370">Breakfast on the go</a><br><a href="http://www.sci-mx.co.uk/product-a-z/pro2go-duo-bar.html">Protein bar</a><br><a href="http://www.dolphinfitness.co.uk/en/optimum-nutrition-natural-whey-and-oats/21659">Oats &amp; Whey shake</a> (choc with a scoop of almond butter)<br><a href="http://www.tesco.com/groceries/product/details/?id=250926075">Smoked Salmon</a> on 2x wholemeal toast</td>
</tr>
<tr>
<td>10am (gym day only)</td>
<td align="center"><a href="http://www.dolphinfitness.co.uk/en/optimum-nutrition-100-whey-gold-2.2kg/16825">Protein shake</a> (mint or extreme milk choc)</td>
</tr>
<tr>
<td>10:30am</td>
<td align="center">1 precooked <a href="http://www.tesco.com/groceries/product/details/?id=264465356">chicken breast</a> (skin removed)<br><a href="http://www.tesco.com/groceries/product/details/?id=279817782">Sweet chilli chicken</a><br>Additional raw broccoli is optional</td>
</tr>
<tr>
<td>1:30pm / lunch</td>
<td align="center">~150g Chicken &amp; 50g egg noodles + hot sauce<br><a href="https://gist.github.com/remy/7c55ff6fbec15fe88ba3#file-taco-salad-md">Taco salad</a><br><a href="https://gist.github.com/remy/7c55ff6fbec15fe88ba3#file-guac-omlette-md">Guacamole Omelette</a> (looks bad, tastes great!)<br>Mexican chicken salad with avocado <a href="http://www.lachoza.co.uk/">from La Choza</a></td>
</tr>
<tr>
<td>4:15pm</td>
<td align="center"><a href="http://uk.fage.eu/product/yoghurt/total-0-170g">0% fat Total yoghurt</a><br><a href="http://danio.co.uk/">Danio</a><br>Protein bar<br>20-45g Cashew nuts</td>
</tr>
<tr>
<td>6:45pm</td>
<td align="center">Protein shake<br><a href="https://gist.github.com/remy/7c55ff6fbec15fe88ba3#file-mocha-shake-md">Mocha shake</a></td>
</tr>
<tr>
<td>8pm / dinner</td>
<td align="center"><a href="https://gist.github.com/remy/7c55ff6fbec15fe88ba3#file-fajitas-md">Fajita chicken, fresh guacamole &amp; refried beans</a><br>Tescos Healthy Living Oven chicken with refried beans<br>Turkey stuffed peppers<br>Nandos 1/2 chicken &amp; beans<br>Sweet chilli salmon fillet, rocket &amp; 100g of soya beans</td>
</tr>
<tr>
<td>10:30pm / bed<br>(optional)</td>
<td align="center">Vanilla Casein protein shake</td>
</tr>
</tbody>
</table>
<p>I would pre-cook 3-4 lunches (chicken and taco salad) each week (ideally on Sunday, but possibly in the morning when I&#39;ve been slack). I&#39;ve got lots of tupperware and keep it in the fridge (and yeah, the chicken gets dry). I&#39;m definitely weakest at breakfast. I&#39;d love it to be scrambled eggs with salmon flakes, but this has worked for me.</p>
<p>My big pro tip: I have alarms reminding me when I need to eat, because without them, I&#39;d just soldier on and forget. Not good.</p>
<div class="update">
<strong>Addendum:</strong> since I wrote this post quite a while ago now (even though I&#39;ve just published it), I&#39;ve since changed my diet. For 2 months I increased from 1,500kcals to 2,000kcals, and as of this week, I&#39;m trying to hit 2,200kcals.

I&#39;m eating larger meals throughout the day in place of the &quot;snack&quot; bars, and my breakfast is around 400-500kcals via a <a href="https://gist.github.com/remy/7c55ff6fbec15fe88ba3#file-oatmea-choco-banana-strawberry-shake-md">shake I make</a>, which I rather like.
</div>

<h2>Resources</h2>
<p>Here&#39;s a few resources I found useful:</p>
<ul>
<li><a href="http://www.nerdfitness.com/">Nerd fitness</a> - there&#39;s a few inspiring stories along with some good information</li>
<li><a href="http://www.amazon.co.uk/4-Hour-Body-uncommon-incredible-superhuman/dp/0091939526/ref=sr_1_1">The 4 Hour Body</a></li>
<li><a href="http://www.myfitnesspal.com/">My Fitness Pal</a> - site and app for Android &amp; iPhone, allowing you to scan barcodes to determine your macros</li>
<li><a href="http://thedk.co.uk/">The Diet Kitchen</a> - just recently found this &amp; <a href="https://www.youtube.com/user/thedietkitchen">youtube channel</a>, but lots of good looking recipes available</li>
<li>Kamil Ogórek&#39;s <a href="http://kamilogorek.pl/nutrition/">nutrition</a> &amp; <a href="http://kamilogorek.pl/training/">training</a> resources</li>
</ul>
<h2>Questions?</h2>
<p>If this is useful to anyone, that&#39;s awesome. If you have <strong>any</strong> questions, please do ask in the comments below, I&#39;m more than happy to answer or update the blog post with more details.</p>
]]></content:encoded></item><item><title>I'm a web developer. Not an engineer.</title><guid isPermaLink="false">i-am-web-developer</guid><link>http://remysharp.com/2015/02/26/i-am-web-developer</link><pubDate>Thu, 26 Feb 2015 11:00:00 +0000</pubDate><description><![CDATA[Something I’m starting to realise and accept for myself: I’m a web developer. Not an engineer. Mostly an approach &amp; understanding difference

– Me, 6-Feb 2015
This seemed to strike a chord with a few people, and others asked if I could embellish on those thoughts. So here it is.]]></description><content:encoded><![CDATA[
<blockquote>
<p>Something I’m starting to realise and accept for myself: I’m a web developer. Not an engineer. Mostly an approach &amp; understanding difference</p>
</blockquote>
<p>– Me, <a href="https://twitter.com/rem/status/563708407337996288">6-Feb 2015</a></p>
<p>This seemed to strike a chord with a few people, and others asked if I could embellish on those thoughts. So here it is.</p>
<h2>On titles</h2>
<p>&quot;We&quot; love titles. Personally, in the last 5 years, I&#39;ve preferred the <em>sound</em> of being an engineer, or a JavaScript engineer. I actually quite like <em>software designer</em>. But let&#39;s face it, it&#39;s all fluff.</p>
<p>Actually, where titles aren&#39;t fluff, is when you work in a larger company. Quite often titles relate directly to pay scales. I digress.</p>
<p>The <em>engineer</em> bit is a little less fluffy and does actually carry meaning.</p>
<h2>Engineers</h2>
<p>Calling yourself an engineer, when you&#39;re not actually qualified as an engineer is <em>sort of</em> a no-no. In fact, there&#39;s some <a href="http://en.wikipedia.org/wiki/Engineer#Regulation">regulation</a> around the engineering titles - and certainly in the UK (according to the Wikipedia page), there&#39;s been petitions to protect the title.</p>
<p>Ignoring the regulations, to me, engineers are smart, educated (ideally in a form of engineering...) and specifically: solving complex computer engineering problems.</p>
<p>In a conversation (over twitter) I was having with <a href="https://twitter.com/trek">Trek Glowacki</a>, midway he replied with:</p>
<blockquote>
<p>Take a step back and understand the real engineering goal: SRP</p>
</blockquote>
<p>I wasn&#39;t aware of any engineering goal, nor what <a href="http://en.wikipedia.org/wiki/Single_responsibility_principle">SRP</a> stood for, nor did I <em>really</em> understand what the Wikipedia page was saying to me.</p>
<p>Honestly, I kind of feel out of my depth amongst engineers aka those people who *really&quot; took the time to study computer science and grok the shit out of it.</p>
<h2>I am web developer</h2>
<p>I don&#39;t know why I thought it was uncool to be a &quot;web developer&quot;. Perhaps because it&#39;s utterly vague.</p>
<p>What &quot;web developer&quot; <em>does</em> mean <em>to me</em> though, is this:</p>
<p>Someone who writes code for browsers. Likely from the school of view source, is comfortable with drop-in libraries, understands standards and <em>best practice</em> techniques. But mostly, <strong>a tinkerer.</strong></p>
<h2>I am not alone</h2>
<p><img src="https://remysharp.com/images/tbl-developer.jpg" alt="Tim Berners-Lee: web developer"></p>
<p>The picture above is an (infamous) screen grab from the <a href="http://www.webplatform.org/">Web Platform</a> introduction <a href="https://www.youtube.com/watch?v=Ug6XAw6hzaw">video</a>. Of Sir Tim Berners-Lee. The <em>creator</em> of The Web.</p>
<p>I saw a lot of posts and tweets suggesting that this was a joke, or a disservice to his work, or that the title was utterly understated.</p>
<p>I&#39;m not sure it was. There&#39;s no doubt that this man is responsible for a <em>lot</em> more, but he <em>is</em> The Web Developer.</p>
<p>I&#39;m proud to say that I work on that same web. Making it better (and sometimes, perhaps, a little worse).</p>
<h2>Embrace it</h2>
<p>I&#39;ve personally learnt my web development skills over a long period of time and nearly entirely through trial and error. I suspect most of us have.</p>
<p>Being a web developer doesn&#39;t have to mean you have to be a JavaScript wiz, or that you <em>don&#39;t</em> touch the server side. By virtue of tinkering, it&#39;s quite likely you&#39;re getting better at <em>all</em> these things.</p>
<p>Coming to this realisation is by no means a slur against those people who call themselves engineers. If you do, it&#39;s quite likely I already have a great deal of respect for your knowledge and understanding if I&#39;ve come across your work already.</p>
<p>As for me, I&#39;m proud to say: I am a web developer. I am a tinkerer.</p>
]]></content:encoded></item><item><title>What do you mean, you don't like IE6...X?</title><guid isPermaLink="false">you-dont-like-iex</guid><link>http://remysharp.com/2015/02/06/you-dont-like-iex</link><pubDate>Fri, 06 Feb 2015 16:00:00 +0000</pubDate><description><![CDATA[I wrote an offsite blog post entitled &quot;What do you mean, you don&#39;t like IE6? Really?&quot; back in 2011. The post is still relevant, but in the last 4 years I&#39;m pretty confident that the complaint isn&#39;t IE6, it&#39;s IE7, or IE8, or...you get the idea.
So, for your special reading pleasure, I&#39;ve made it so that this post can updated to your particular IE complaint.]]></description><content:encoded><![CDATA[
<p>I wrote an offsite blog post entitled &quot;What do you mean, you don&#39;t like IE6? Really?&quot; <em>back in 2011</em>. The post is still relevant, but in the last 4 years I&#39;m pretty confident that the complaint isn&#39;t IE6, it&#39;s IE7, or IE8, or...you get the idea.</p>
<p>So, for your special reading pleasure, I&#39;ve made it so that this post can updated to your particular IE complaint.</p>
<p>Which IE don&#39;t you like: <select id="ie-selection" style="font-size: 20px; width: 100px"></p>
<p><option>ALL THE BROWSERS!!!</option></p>
<p><option>IE5</option></p>
<p><option selected>IE6</option></p>
<p><option>IE7</option></p>
<p><option>IE8</option></p>
<p><option>IE9</option></p>
<p><option>IE10</option></p>
<p><option>FUTURE IE!</option>
</select></p>
<script>
window.onload = function () {
  $('#ie-selection').on('change', function () {
    $('.browser').text(this.value);
  });
};
</script>

<hr>
<p>Today I read the latest in the long, long, long line of why I won&#39;t support <strong class="browser">IE6</strong>. How fucking droll. If <strong class="browser">IE6</strong> support is part of your job or your contract - then that&#39;s what it is, that&#39;s the job, that&#39;s the challenge of your work.</p>
<figure>
<figure><img class="withcredit" src="https://farm4.staticflickr.com/3609/3629069606_3d1a1cd8fb_b.jpg" title="Photo by John Martz"><figcaption class="credit">Photo by John Martz / <a href="http://RobotJohnny.com">RobotJohnny.com</a></figcaption></figure>
</figure>

<hr>
<p>I am sick and tired of the same old boring posts and even web sites dedicated to why <strong class="browser">IE6</strong> should die. We all know <strong class="browser">IE6</strong> should die. Microsoft knows <strong class="browser">IE6</strong> should die. Heck, even <strong class="browser">IE6</strong> knows it needs to die. It&#39;s been walking around like a fucking zombie for years.</p>
<p>See now, here&#39;s the thing: not one person today installs <strong class="browser">IE6</strong> as their main browser. In fact, given the choice, I&#39;m willing to bet that no person would choose to use <strong class="browser">IE6</strong> as their main browser over any other browser. But that&#39;s not the problem. So that we&#39;re clear: nobody is fucking choosing to use <strong class="browser">IE6</strong> and they&#39;re certainly not using that browser just to piss you off!</p>
<p>While we&#39;re at it - when <strong class="browser">IE6</strong> does eventually die, who&#39;s going to do the find and replace on all the blog posts from IE6 to IE7, then IE7 to IE8, etc.?</p>
<hr>
<p>It&#39;s a simple matter of when XYZ company bought all their machines for the users back in the XP / <strong class="browser">IE6</strong> days, it cost them a butt load of money. Companies don&#39;t like spending money where they (think) they don&#39;t have to. So upgrading all those PCs again is not a priority for them. Remember that upgrade comes with support, maintenance, down time, etc - something that costs (another butt load of) money.</p>
<p>I ran some training once fairly recently at an institute of science where the developers told me that the browser with the highest usage, by far, was <strong class="browser">IE6</strong>. It was their job to support that browser.</p>
<p>Their job. They get paid. If you don&#39;t want to support <strong class="browser">IE6</strong> - then don&#39;t. Nobody is twisting your arm to accept that job as a freelancer. If you&#39;re so against <strong class="browser">IE6</strong> and you&#39;ve got a full time job - I do hope you brought that up during the interview - and if not, if you&#39;re really hate <strong class="browser">IE6</strong> - you could quit and find another job, right?</p>
<p>The fact is that <strong class="browser">IE6</strong> is a difficult environment because it&#39;s unsupported, particularly against todays requirements of web sites. So we charge more for it.</p>
<p>If your client is building a brand new product, and unless they have hard stats showing they need to support <strong class="browser">IE6</strong>, you&#39;ve no reason to support older browsers, and there&#39;s lots of ways of determining the types of browser usage those potential users will have. However, if they&#39;re an existing company, and they do have <strong class="browser">IE6</strong> traffic that warrants supporting by their business - then that&#39;s just part of your job.</p>
<p>Some development teams are the size they are, and employ the people they do just because of browsers like IE. If it weren&#39;t hard, there&#39;d be a bunch of people out of the job.</p>
<hr>
<p>Developing for the web requires that you know how browsers work. The challenge of the job is making those web sites work everywhere. Knowing the ins and outs of browsers is what separates a regular Joe Average apart from the Mr James Awesome. If you don&#39;t want to learn about <strong class="browser">IE6&#39;s</strong> quirks (or IE7 or IE8 or IE9&#39;s) then don&#39;t. Someone else will take the work.</p>
<p>As for me, I&#39;ll be holding my breath waiting for the next reason why <strong class="browser">IE6</strong> should die - like it&#39;s not documented well enough already.</p>
<p><small>Reposted from <a href="http://remy.tumblr.com/post/8334086394/what-do-you-mean-you-dont-like-ie6-really">rem @ &gt; 140 characters</a></small></p>
]]></content:encoded></item><item><title>Lessons learnt from nodemon 1.3</title><guid isPermaLink="false">lessons-learnt-from-nodemon-1-3</guid><link>http://remysharp.com/2015/02/02/lessons-learnt-from-nodemon-1-3</link><pubDate>Mon, 02 Feb 2015 11:00:00 +0000</pubDate><description><![CDATA[I recently pushed out an update to nodemon going from 1.2 to 1.3 containing a few new features and insights which I wanted to share here.]]></description><content:encoded><![CDATA[
<p>I recently pushed out an update to <a href="https://www.npmjs.org/nodemon">nodemon</a> going from 1.2 to 1.3 containing a few new features and insights which I wanted to share here.</p>
<p>Along with a slew of <a href="https://github.com/remy/nodemon/compare/v1.2.1...v1.3.6">changes and bug fixes</a> came three interesting changes:</p>
<ol>
<li>Support for events at the nodemon.json level allowing growl-like notifications</li>
<li>Virtual machine support where the clock inside the container was different to the host clock</li>
<li>Support piping commands in the exec (a trick I learnt from the <a href="https://github.com/npm/npm/">npm source</a>)</li>
</ol>
<h2>Exposing events to nodemon.json</h2>
<p>When you require nodemon you can listen for <a href="https://github.com/remy/nodemon/wiki/Events#states">events</a>. Since the contents of <code>nodemon.json</code> gets mapped directly to <code>nodemon.config.options</code> I was able to read an event property and easily bind those events to spawn your customised commands:</p>
<pre><code class="language-js">Object.keys(config.options.events).forEach(function (key) {
  nodemon.on(key, function () {
    spawn(config.options.events[key], config, [].slice.apply(arguments));
  });
});</code></pre>
<p>Now from inside a global <code>nodemon.json</code> (that lives in my home directory) I can add the following to trigger OS level notifications that tell me my server restarted:</p>
<pre><code class="language-json">{
  &quot;events&quot;: {
    &quot;restart&quot;: &quot;osascript -e &#39;display notification \&quot;app restarted\&quot; with title \&quot;nodemon\&quot;&#39;&quot;
  }
}</code></pre>
<h2>Virtual machines / Docker</h2>
<p>Using docker containers has become increasingly popular. Nodemon is used in all sorts of situations but more and more people found that nodemon wasn&#39;t working in the VM. This is almost entirely due to the fact that the container often has a completely different datetime to the host, and in fact what was happening is the host would touch the file and the timestamp to the container, was in the <em>future</em>!</p>
<p>So how do you work out the time drift between the container and the host?</p>
<p>After a lot of poking and randomly testing things, it turns out it&#39;s pretty easy: touch the the file from inside the container, then compare the modified time to the system time.</p>
<p>For some reason (in my tests and others), the container would use the host datetime when touching files.</p>
<p>So now nodemon upon startup, touches a file and if the timestamp is significantly off the system clock, it warns that there&#39;s a drift and adjusts how it searches for changes on the file system.</p>
<pre><code class="language-text">[nodemon] virtual machine clock offset: 12h31m58s
[nodemon] v1.3.6
...</code></pre>
<h2>Supporting piped commands</h2>
<p>Both the <code>exec</code> and the event commands now support being able to pipe commands together ala Unix as such:</p>
<pre><code class="language-bash">nodemon -x &#39;tap test/**/* | tap-spec&#39;</code></pre>
<p>Now nodemon will restart my tests and run them through tap-spec.</p>
<p>The  way this works was lifted from the npm source code.</p>
<p>For Unix based systems you run:</p>
<pre><code class="language-bash">sh -c &quot;tape test/**/* | tap-spec&quot;</code></pre>
<p>In windows it&#39;s:</p>
<pre><code class="language-bash">cmd /c &quot;tape test/**/* | tap-spec&quot;</code></pre>
<p>Then just drop that into the <code>spawn</code> function and you&#39;re good to go.</p>
<h2>Update</h2>
<p>So go ahead and get the latest nodemon via <code>npm install -g nodemon@latest</code> — and if you feel inclined, maybe ping npm folk to get nodemon on their front page too!</p>
]]></content:encoded></item><item><title>&quot;Why I don't like open source&quot; – my thoughts</title><guid isPermaLink="false">dont-like-open-source</guid><link>http://remysharp.com/2015/01/09/dont-like-open-source</link><pubDate>Fri, 09 Jan 2015 12:30:00 +0000</pubDate><description><![CDATA[This morning&#39;s walk was accompanied by Tiago Rodrigues (excellent) curation and commentary on Adam Yeats tweets on open source and (mostly) James Seymour-Lock&#39;s replies.
Please read it. Carefully. Get all the way through and reserve judgement (if any) for the end.
It&#39;s not the first time Adam&#39;s thoughts have inspired a blog post either! These are my thoughts on open source, contributing and the points raised in the discussion.]]></description><content:encoded><![CDATA[
<p>This morning&#39;s walk was accompanied by <a href="https://twitter.com/trodrigues">Tiago Rodrigues</a> (excellent) curation and commentary on <a href="https://twitter.com/adamyeats">Adam Yeats</a> tweets on open source and (mostly) <a href="https://twitter.com/JamesSLock">James Seymour-Lock</a>&#39;s replies.</p>
<p><a href="https://storify.com/trodrigues/why-i-don-t-like-open-source-a-play-in-3-acts">Please read it</a>. Carefully. Get all the way through and reserve judgement (if any) for the end.</p>
<p>It&#39;s not the first time Adam&#39;s thoughts have inspired a <a href="/2012/12/18/contributing-to-the-web-community">blog post</a> either! These are my thoughts on open source, contributing and the points raised in the discussion.</p>
<p><small>This post is partly edited, but quite long, so might not be 100% coherent. For that, I&#39;m sorry!</small></p>
<h2>Our web community distorts expectations</h2>
<p>(Not) contributing to open source isn&#39;t the problem. The pressure coming from external and internal sources telling us that we should be contributing is invalid, in that <strong>it should not exist</strong>, but it does.</p>
<p>How <em>we think</em> people see us is only a reflection of how we feel about ourselves. The project getting the most retweets today is not representative of real work. Nor is the person with the most followers the better human being.</p>
<p>There is distortion in the web community that you need to learn more, contribute more, work more, know everything, be on the latest technology, and so on. <strong><em>Unsubscribe</em></strong>. Unfollow. Turn off alerts and notifications (or at least make your &quot;quiet hours 6pm-9am). <em>Find other human beings</em>.</p>
<p>I want to say that Adam&#39;s tweets are not the fault of open source, but our industry&#39;s distortion. But his tweets and the subsequent replies prompted me to also write down my thoughts about open source that I&#39;ve been mulling over the last few years.</p>
<h2>What does open source really mean?</h2>
<p>It means <a href="https://github.com/nickdesaulniers/What-Open-Source-Means-To-Me">different things to different people</a>. That&#39;s okay.</p>
<p>To me, it means:</p>
<blockquote>
<p>Welcome. Welcome to this code I wrote. Help yourself to bits you like or need. Help make it better for others. Help make it yours. Help make me better with your suggestions, changes or discussion. Use the code in any way you want, in ways I never thought of. And if the projects I created lives on without me, then open source has worked.</p>
</blockquote>
<p><em>You</em> need to decide what it means to you, and what it looks like. Which leads me to ask: <em>is a project really open source</em>?</p>
<h2>There are two kinds of open source projects</h2>
<p>There&#39;s the big, high profile projects and then there&#39;s <em>everything</em> else.</p>
<p>When I&#39;d hear &quot;open source&quot;, I&#39;d think: Linux, Apache, Firefox, bootstrap, ember, node, etc. i.e. big fucking high profile massive open source projects with a fuck tonne of code*.</p>
<p><small>* Okay, there&#39;s also a decent number of sensible codebase sized projects that are used a lot, passport for node for instance</small></p>
<p>This is <em>Type One</em>.</p>
<p><em>Type Two</em> open source projects are the kind of project where the source is open, and the license is &quot;meh&quot;/&quot;whatever I always use but don&#39;t really understand&quot;. For me this is MIT. But that&#39;s beside the point.</p>
<p>The source is available. <em>Just like the web</em>. View source. It&#39;s the kind of open source that I&#39;m familiar with (obviously there&#39;s discussions around licenses, but that&#39;s for another day).</p>
<p>Type Two projects: the kind where the source is just somewhere on the web, is the kind that, if we&#39;re honest, hardly anyone else is going to contribute to. I&#39;ll be lucky if anyone actually uses it, let alone skims the code.</p>
<p>This second type, it could be closed source. It could be something that was never uploaded to the web. But it was. This is the majority of open source projects today. Very much like the late 90s when there were sites offering JavaScript ...files (because library and framework really doesn&#39;t apply) that gave you menus, hover effects, basic whiz bang stuff. Except now it&#39;s up on Github or npm (or whatever you Ruby folk use!).</p>
<p>If someone sends a pull request to one of these projects, there&#39;s a few things that can happen: it&#39;s ignored/forgotten about or it&#39;s blindly merged &quot;meh, cool&quot; (there&#39;s other outcomes too!).</p>
<p>For me, putting code in github as &quot;open source&quot; is for two main reasons: 1) so if I lose the code locally, I can find it again (fingers crossed Github doesn&#39;t vanish too quickly), 2) I can&#39;t be arsed to pony up the pitiful amount of dollars for more private repos.</p>
<p>The majority of the repo owners on the type one projects are <em>companies</em>. It&#39;s their product. The majority of type two, are individuals. Let&#39;s remember that perspective. Contributing to the small ones isn&#39;t a big deal and potentially contributing to the big ones might be like pissing in the ocean.</p>
<h2>Contributing to open source</h2>
<p>I can&#39;t speak for Adam, but it <em>sounds</em> like he&#39;s either felt pressure to contribute to some projects either externally or internally. I could be way off based, but I <em>do</em> know people who&#39;ve felt this way. Heck, I feel this internal pressure sometimes.</p>
<p>Contributing (code) to the Type One projects isn&#39;t something you can do with a few hours. So seriously, if you feel this pressure: stop it.</p>
<p>It takes hours, if not days to become familiar with the codebase. Then creating a bug fix or a new feature isn&#39;t quite as simple as &quot;hacking some code in&quot;. If it&#39;s a high profile project, it&#39;ll come with tests and coding guidelines. That&#39;s more work, and you&#39;ve not even contributed a single line yet.</p>
<p>For context, in late-2000s, I partook in a <a href="https://web.archive.org/web/20130512035317/http://docs.jquery.com/JQuerySprint">jQuery day long sprint</a> to fix bugs. I&#39;d say I knew jQuery pretty damn well at the juncture. By the end of the sprint, I&#39;d managed to confirm just one bug, and <em>pretty much</em> have an idea of what caused it.</p>
<p>&quot;Contributing to open source&quot; is a long term commitment, and you do have to pick and choose. There&#39;s a few people like Substack filling npm with his node modules is great, perhaps reinventing every wheel, but he&#39;s also doing it to <a href="https://gratipay.com/substack/">cover his living</a>. But these people are the exception. This isn&#39;t a lifestyle that&#39;s available to most people (and frankly, npm is running out of useful names for projects!).</p>
<p>Ask yourself what is open source. Ask yourself if you want to contribute to that, and if you do (want to contribute) ask yourself <em>why</em>.</p>
<h2>Hiring purely based on open source contributions</h2>
<p>...is bullshit.</p>
<p>But <em>maybe</em>, maybe some companies will exclusively hire you based on your open source contributions. Honestly, if that&#39;s the case, it&#39;s more likely you&#39;re not applying for the job, and in fact the company is head hunting you.</p>
<p>It <em>is</em> true that an &quot;open source&quot; project is seen as a reference of work. But it&#39;s also a <em>stale</em> reference of work. And importantly, it&#39;s not the only reference.</p>
<p>Take my open source <a href="https://github.com/remy/inliner">inliner</a> project for instance. The code is appalling. There&#39;s outstanding open issues <em>and</em> pull requests. This is an open source project that is <em>not</em> representative of my current skills. Yet it&#39;s still open source. I wouldn&#39;t put it forward as my best work.</p>
<p><a href="https://github.com/jsbin/jsbin">JS Bin</a> is probably a better example of my work, but honestly, the code is not my best foot forward. In fact, I&#39;ve had job offers based on the companies associating me with the project, but I know for certain that they&#39;ve not looked at the code.</p>
<p>Hiring decisions are <em>mostly</em> based on some early criteria that&#39;s utterly arbitrary. Like &quot;do they have a degree&quot;, or &quot;do they have a github account&quot;, or &quot;what is their personal interest&quot;. The reason: to reduce 100 CVs down to a manageable number that you can actually interview.</p>
<p>When I interviewed <a href="https://twitter.com/allouis_">Fabien O&#39;Carroll</a> in late 2013 he had limited open source projects I could look at (which I would have skimmed to get an idea of scope of projects he works on), which is fine, and he couldn&#39;t really share his company&#39;s code.</p>
<p>With <em>all</em> my interviewees I asked them to write me a hangman game in JavaScript, and not to spend more than 2-4 hours on it (in their own time). I would pay each an honorarium for their time, because it was likely they were already employed and would have to do it <em>out of hours</em>. Personal time is valuable, and <strong>no one has an automatic right to it</strong>.</p>
<p>His code was decent, but that&#39;s not what got him the job. During the interview, when asked if there was anything else he was interested in, he struggled then eventually mentioned he built a chess timer (in wood) that he could use with his then-girlfriend. <em>That&#39;s</em> what got him the job, and that same sentiment is what I saw over the following year. That detail doesn&#39;t belong on github, isn&#39;t part of our community, but <em>is</em> part of an interview.</p>
<p>Never undervalue what you do. Everyone is unique. Some people aren&#39;t right for some jobs, but you github streak says positive <em>and</em> negative things.</p>
<h2>If you can&#39;t contribute: you&#39;re not part of the community</h2>
<p>Arguing that someone should get a jobsworth position* because the work 9-5 (or whatever extra overtime) is bollocks. It&#39;s not the first time I&#39;ve seen it either. This kind of sentiment is utterly selfish and narrow minded.</p>
<p><small>* It&#39;s worth pointing out that James&#39; tweet was <a href="https://twitter.com/JamesSLock/status/553546788779859968">between friends</a></small></p>
<p>The people who have a high chance of working on extra curricular projects are likely to be single, not terribly social and in their 20s. Why? Because when you&#39;re on your own and younger, you have more energy, and you need less sleep. When I was in my 20s (and married) I was hacking until 2am in the morning. What was my code like between 10pm and 2am? Shit. In fact, it&#39;s taken me years to realise that when I&#39;m not on form (i.e. past 6pm) that it takes me twice as long, if not more, to complete a simple task. A complex task is unlikely to get fixed.</p>
<p>Our brains fuck with us when we deprive it of rest. Tell yourself you have RSI. If you have RSI, you rest. You move away from typing at a keyboard because if you push it, it hurts. Take <em>that</em> approach.</p>
<p>Now that I&#39;ve got young kids, when I leave the office, someone will ask &quot;what are you up to this evening?&quot;. The same as every other evening: I help put the kids to sleep, I cook (or help cook), I eat, I got to bed. I love that I&#39;m with my family, and it&#39;s enough for me. There is <em>no time</em> for coding in that evening.</p>
<h2>My thoughts</h2>
<p>I&#39;ve got another post that I&#39;m writing about &quot;what I love about the web&quot;, which is sort of related: <strong>enjoy what <em>you</em> do</strong>. Question where the pressure comes from. If possible, focus on what you love and ignore the noise of &quot;hey, look at <em>my</em> cool thing&quot;.</p>
<p>There <em>is</em> this weird pressure to get a &quot;name&quot; in our industry. But fuck, seriously, <strong>you are amazing</strong>. You work hard and you should be proud of your work irrespective of whether others can see it in the open.</p>
<p>You come first, not your code or someone else&#39;s project: you.</p>
<p>For me, my family comes first. Work and code isn&#39;t even a distant second. It&#39;s taken me many years of working silly hard and silly hours to work that out. Now that I understand that, life is better.</p>
]]></content:encoded></item><item><title>Reboot</title><guid isPermaLink="false">reboot</guid><link>http://remysharp.com/2015/01/05/reboot</link><pubDate>Mon, 05 Jan 2015 16:00:00 +0000</pubDate><description><![CDATA[The last year I&#39;ve made a conscious effort to focus development efforts in JS Bin, and that&#39;s exactly what I did for over 8 months.
I had the great pleasure of hiring Giulia Alfonsi and Fabien O&#39;Carroll. Giulia&#39;s contracted ended after 6 months and Fabien is now headed to greener pastures.
So now I have a 4 person office to myself. With that burning a hole in the business pocket, I&#39;ve decided to completely reboot my business.
I&#39;m shutting down the office and returning to solo working and surfing from co-working space to coffee shops with the aim of working on hugely diverse projects and contributing more to the web community via blogging, videos and training.
Exciting next opportunities
Starting in January 2015, I&#39;ll continue to work alone again, tinkering in side projects, but more importantly, returning to client development, consultancy and training.
This means that I can be more nimble in my client work, jumping from project to project and working on all kinds of things (previously it ranged from Christmas Google Map projects, to WebRTC demos, to Node &amp; WebSocket based games, to JavaScript reviews and training).
Why you&#39;d hire me
I&#39;ve been working on the web professionally since 1999 (and several years before that on personal experiments) and I believe that length of experience is a major contributor to my skills. Often I was thrown into unknown (technical) waters, and it was sink or swim with nothing in between. From that I know my work always focuses towards practicality over perfection.
Often when I&#39;ve been brought in to review existing code along with the review I&#39;ll do my best to impart the techniques and tools I used to review, diagnose and fix. My aim isn&#39;t to swoop in and amaze, it&#39;s to help your team and help validate their skills.
What&#39;s next?
Get in touch if you want to discuss a project or idea.
I&#39;m going to continue to invest in JS Bin and I&#39;ll be launching Confwall in the next few weeks, a commercial offering of a conference wall with tweets, schedule and announcements.
Beyond that, like I said, I&#39;ll be blogging and posting more technical videos in the coming year.]]></description><content:encoded><![CDATA[
<p>The last year I&#39;ve made a conscious effort to focus development efforts in JS Bin, and that&#39;s exactly what I did for over 8 months.</p>
<p>I had the great pleasure of hiring Giulia Alfonsi and Fabien O&#39;Carroll. Giulia&#39;s contracted ended after 6 months and Fabien is now headed to greener pastures.</p>
<p>So now I have a 4 person office to myself. With that burning a hole in the business pocket, I&#39;ve decided to completely reboot my business.</p>
<p>I&#39;m shutting down the office and returning to solo working and surfing from co-working space to coffee shops with the aim of working on hugely diverse projects and contributing more to the web community via blogging, videos and training.</p>
<h2>Exciting next opportunities</h2>
<p>Starting in January 2015, I&#39;ll continue to work alone again, tinkering in side projects, but more importantly, returning to client development, consultancy and training.</p>
<p>This means that I can be more nimble in my client work, jumping from project to project and working on all kinds of things (previously it ranged from Christmas Google Map projects, to WebRTC demos, to Node &amp; WebSocket based games, to JavaScript reviews and training).</p>
<h2>Why you&#39;d hire me</h2>
<p>I&#39;ve been working on the web professionally since 1999 (and several years before that on personal experiments) and I believe that length of experience is a major contributor to my skills. Often I was thrown into unknown (technical) waters, and it was sink or swim with nothing in between. From that I know my work always focuses towards practicality over perfection.</p>
<p>Often when I&#39;ve been brought in to review existing code along with the review I&#39;ll do my best to impart the techniques and tools I used to review, diagnose and fix. My aim isn&#39;t to swoop in and amaze, it&#39;s to help your team and help validate their skills.</p>
<h2>What&#39;s next?</h2>
<p><a href="http://leftlogic.com/contact">Get in touch</a> if you want to discuss a project or idea.</p>
<p>I&#39;m going to continue to invest in JS Bin and I&#39;ll be launching <a href="http://confwall.com">Confwall</a> in the next few weeks, a commercial offering of a conference wall with tweets, schedule and announcements.</p>
<p>Beyond that, like I said, I&#39;ll be blogging and posting more technical videos in the coming year.</p>
]]></content:encoded></item><item><title>My 2014</title><guid isPermaLink="false">my-2014</guid><link>http://remysharp.com/2014/12/31/my-2014</link><pubDate>Wed, 31 Dec 2014 12:00:00 +0000</pubDate><description><![CDATA[As with previous years (barring 2008, oddly), I&#39;ve tried to wrap up the highlights of my year for future Remy&#39;s reading pleasure.]]></description><content:encoded><![CDATA[
<p>As with previous years (barring 2008, oddly), I&#39;ve tried to wrap up the highlights of my year for future Remy&#39;s reading pleasure.</p>
<h2>Professional</h2>
<p>This year has been a mixed bag from a professional stand point, mostly revolving around JS Bin.</p>
<h2>JS Bin</h2>
<p><img src="https://remysharp.com/images/jsbin-t-shirt.jpg" alt="JS Bin"></p>
<p>Back in <a href="/2013/08/14/jsbin-5th-birthday">August 2013</a> I decide that I would try to focus my full time efforts on JS&nbsp;Bin, and after speaking to many individuals at conferences and events, I decided that the right path would be to add subscription based Pro accounts.</p>
<p>It took 8 months to actually get to launch. A mistake. It should have taken 2-3 months, and I shouldn&#39;t have been so hell bent on getting it perfect. Putting 100% effort into a project and 3 full time developers, with no capital and no income meant a pretty serious hit to my own business (Left Logic).</p>
<p>That all said, JS Bin is here to stay. I&#39;ve run it as side project for over 6 years, and I&#39;ll continue to run it that way. There&#39;s production grade servers in place, something like 13 million bins in our database, and a massive 126 million page views since it started and lots of cool stuff still to be done. And the truth is, when it&#39;s fun to work on JS Bin, it&#39;s <em>fun</em>.</p>
<h2>Left Logic</h2>
<p>At the start of the year I took on a new office and I took on two new full time employees <a href="https://twitter.com/allouis_">Fabien O&#39;Carroll</a> and <a href="https://twitter.com/electric_g">Giulia Alfonsi</a>, and also <a href="https://twitter.com/dcgauld">David Gauld</a> as a part time/freelancer.</p>
<p><img src="https://remysharp.com/images/leftlogic-team-2014.jpg" alt="Left Logic 2014 team"></p>
<p>But as the year went on, Giulia&#39;s 6 month contract ended and Fabien was tempted away by local Brighton company, Brandwatch (I&#39;m proud to say after he turned them down a few times first).</p>
<p>It&#39;s been a huge pleasure working with Giulia and Fabien - they&#39;re both great people to know and damn good developers. David (equally superb developer) led the <a href="http://leftlogic.com">Left Logic</a> redesign and is continuing to (remotely) contribute to Confwall (a new product from Left Logic).</p>
<p>As 2015 starts, there&#39;s no point in having an office <em>just</em> to myself, so I&#39;m selling all the kit, closing the office and returning to a roaming desk, for better or worse!</p>
<h2>Speaking &amp; Travelling</h2>
<p>Over the last few years I&#39;ve been reducing my public speaking further and further down. This year I only gave two different talks at only three events.</p>
<p>I&#39;m not terribly proud of the talks either, and I feel like they were either duff notes or bombed entirely. Obviously I have a different perspective on things from the stage, but it&#39;s definitely put me off speaking for a while. I realise this is all subjective, but it&#39;s not a great feeling when you put yourself out there only to feel crappy about it.</p>
<p>I did do an epic write up of my <a href="/muddling-my-way-through-real-time">real-time talk on my blog</a>, which I&#39;m pretty proud&nbsp;of.</p>
<p>On the flip side though, I did spend more time attending events just to learn. Oddly, I had quite a few people exclaim &quot;are you speaking?!&quot;. That&#39;s cute, but there&#39;s certain perks to not speaking: like <em>not speaking</em>!</p>
<p>Particular highlights for me were:</p>
<ul>
<li><a href="https://2014.dareconf.com/mini/london">Dareconf mini</a> (London, UK)</li>
<li><a href="https://edgeconf.com/2014-london">Edge London</a> (London, UK)</li>
<li><a href="http://www.hybridconf.net/">Hybrid Conf</a> (Stockholm, Sweden)</li>
<li><a href="http://www.smartwebconf.com/">SmartWeb</a> (Bucharest, Romania - where I also spoke)</li>
<li><a href="http://2014.jsconf.eu/">JSConf EU</a> (Berlin, German - more for the people &amp; conversations)</li>
</ul>
<h2>#ffconf, <small>aka Full Frontal</small></h2>
<p>This year, our little event sold in two batches, going in 6 and 3 minutes. Insane.</p>
<p>I was quite nervous about this year because there&#39;s so always so much pressure to curate an event that&#39;s better than the last. Every year has been so amazing that I find it hard to think we&#39;ll top the previous year.</p>
<p>I was wrong to be nervous.</p>
<figure><img class="withcredit" src="https://remysharp.com/images/ffconf-2014.jpg" title="Photo by Drew McLellan"><figcaption class="credit">Photo by Drew McLellan</figcaption></figure>

<p>The event was absolutely amazing and thankfully I wasn&#39;t the only one to think so, <em>everyone</em> I spoke to felt this was the best yet. <a href="http://www.outsidethepage.co.uk/full-frontal-2014/">People</a> <a href="http://www.uvd.co.uk/blog/full-frontal-2014-highlights/">even</a> <a href="http://kyan.com/blog/2014/11/11/full-frontal-2014">blogged</a>!</p>
<p>See for yourself - all <a href="https://www.youtube.com/playlist?list=PLXmT1r4krsTqrwW2jjXIXuCtFQ-5BIn-s">eight talks from ffconf are available on YouTube</a>.</p>
<h2>Side Projects</h2>
<p>Although there&#39;s not as many side projects as I&#39;d like this year, it&#39;s clear to me that JS Bin has been consuming my focus for the large part of the year, and that&#39;s <em>okay</em>!</p>
<ul>
<li><a href="https://confwall.com">Confwall</a> - a productised version of the twitter wall I&#39;ve run at ffconf for the last 6 years. Currently open to early beta registrations.</li>
<li><a href="https://apps.getpebble.com/applications/53ff41ed8cdf37902b000050">Rest pebble app</a> - a native C app for the Pebble watch that lets me quick set rest timers at the gym.</li>
<li>Moved my blog from WordPress (to a <a href="http://harpjs.com/">Harp</a>/custom node app) and resumed blogging again - something I&#39;ve wanted to do for a long time. It&#39;s also all up on <a href="https://github.com/remy/remysharp.com">github</a> and I wrote up the process: <a href="/harp-pt1">part1</a>, <a href="/harp-pt2">part2</a>. I&#39;m most proud of the <a href="/archive/">archive</a> page.</li>
<li>nodemon 1.0 - then pretty much abandoning it for a 11 months and revisiting to add some sweet functionality (look out for 1.3.x in the new year)</li>
<li>Introducing HTML5 - this is <em>still</em> in the works to be published for free. Watch this space!</li>
</ul>
<h2>Personal</h2>
<p>In ascending order of personal importance to me:</p>
<h3>Writing</h3>
<p>Rewiring my blog has encouraged me to get writing again. I&#39;ve long fallen out of love with Twitter and wanted to properly return to blogging. As I said earlier, seeing the full <a href="/archive/">archive</a> of my blog has really encouraged me to write again. I&#39;m pretty proud of the 8 years of content.</p>
<p>This year I was also invited to contribute to the Pastry Box project, where I started posting some very personal thoughts, and I&#39;m proud to be <a href="/tag/personal">hosting them here too</a>. The three particularly important ones being <a href="/time-doesnt-heal">Time doesn&#39;t heal</a>, <a href="/velveteen">My Velveteen Rabbit</a> and <a href="/motivation">Motivation</a></p>
<h3>Body</h3>
<p>I&#39;ll spare you the pictures this time (though if you want to brave it, <a href="/my-2013#personal">here&#39;s last year</a>)! <strong>Last year I ended my body fat on 19% (down from 30%).</strong></p>
<p>I&#39;ve been using Fitbit Aria scale, but over the months have lost confidence in their accuracy, so bought a pair of cheap, but more reliable skin callipers.</p>
<p>My body fat at the end of December 2014 (and over the month of December) is <strong>currently 13.8%</strong> (the scales are reading around 10%, which I don&#39;t trust). I also fit into 30 inch jeans and tops that I wore at aged 21 are baggy around my belly (yes, I have a few tops that are over 15 years old!).</p>
<p>My lowest weight (not that I want to be light) was 11 stone. I can see a 6 pack forming (which I&#39;ve <em>never</em> had in all my years).</p>
<p><strong>My biggest deadlift was 170kg</strong>, but in a different session I also tore a disc in my lower back trying to do a superset at 140kg (what had previously been a warm up weight). That cost me a month off the gym and 3 months self imposed ban on deadlifts and squats (along with a chiropractor bill for mostly massage and advice).</p>
<p>Diet is still heavy protein (and I found it quite easy to eat 1500kcals in a day whilst still having 7 meals a day), but I&#39;m trying to add weight at the moment and if I&#39;m honest, I&#39;m struggling!</p>
<p>Oo-oo - and I also got my first few <em>white</em> hairs on my head, mostly due to <a href="/2014/12/16/vatmoss">recent VAT issues</a>!</p>
<p><strong>Bottom line: 13.8% is in the <em>Athletes</em> range of body fat. So the future version of me, reading back, should be damn proud.</strong></p>
<h3>Mind &amp; attitudes</h3>
<p>I don&#39;t really know how to set this down as text, but for me, <em>this year</em> in particular, has been a an eye opener in my attitude and thoughts towards gender and race diversity (there&#39;s more topics for diversity out there, I&#39;m just started).</p>
<p>I found that following more women on twitter (as weird as that sounds, but you know what I mean) has helped broaden my views. I&#39;ve also tried to face and read around topics that I&#39;d normally want to shy away from. It might sound obvious, but if I don&#39;t look and listen: then it&#39;s too easy to ignore and pretend &quot;all is well&quot;.</p>
<p>I always knew that women and people of colour had more to deal with in life, but I didn&#39;t quite want to acknowledge that even though I come from a middle-class family with not very much money, being a white male in Europe with access to computers makes me <em>incredibly</em> privileged. Somehow I thought that the privilege was something to be ashamed of (possibly because I didn&#39;t want people to think that I was rich and spoilt), but the truth is I don&#39;t need to be ashamed, but I do acknowledge this has put me (and many like me) in a position of advantage for what is effectively a lucky coin toss. I see that now.</p>
<p>I&#39;ve found following people like <a href="https://twitter.com/femfreq">Anita Sarkeesian</a> for the last 6 months a huge eye opener and (<a href="https://remysharp.com/2014/10/27/motivation">though I&#39;ve said before</a>) Emma Watson&#39;s <a href="https://www.youtube.com/watch?v=gkjW9PZBRfk">address to the EU is incredibly inspiring</a>.</p>
<p>I&#39;m also <em>trying</em> to read <a href="http://www.amazon.co.uk/The-Gender-Knot-Unraveling-Patriarchal/dp/1439911843/ref=dp_ob_image_bk">The Gender Knot</a>, I&#39;m not far in yet but I hope to take my learnings and pass it on to my children.</p>
<p><strong>Bottom line:</strong> I&#39;m still working this stuff out, and I want to be part of a better system for all.</p>
<h3>Family</h3>
<p>My family is the most important thing to me, and I&#39;m so incredibly proud of Julie, my beloved wife and mother to my amazing kids. 2014 saw the arrival of Seren Tuesday Sharp on 17-April 2014 at 9:37am.</p>
<p>It feels like the last 8 months have flown by, and she&#39;s already near-crawling (basically doing army crawls across the floor), is sitting and pulling herself up, and has 3 teeth to her name. And she has these lovely dark eyelashes that (<em>I</em> think) make her blue eyes look dark and beautiful. I love our littlest one very very much.</p>
<p><img src="/images/seren-2014.jpg" alt="Seren"></p>
<p>Julie and I also celebrated hitting a milestone in our relationship: we&#39;ve now been together for more time in our life than we&#39;ve been apart. 18 years and counting.</p>
<p>I&#39;m hugely proud of my family. I&#39;ll always miss Tia and though she&#39;s not in the picture below, she&#39;s always with us.</p>
<p><img src="/images/family-2014.jpg" alt="Sharp family 2014"></p>
<p>(Yes, getting a picture of the whole family is near impossible, getting a picture of us all smiling, <em>is</em> impossible!)</p>
<h2>2015</h2>
<p>Next year is a big change for me from a work perspective. I go back to running solo and though I&#39;m excited, I&#39;m kinda scared too. I&#39;m hoping that I find inspiration in my work again and get to work on some really interesting projects (and if you want to work with me, <a href="http://leftlogic.com/contact">please do get in touch</a>).</p>
<p>Otherwise, happy new year other-people-that-are-not-future-Remy, I hope your 2014 was a good one, and I hope to see you (not you, future-Remy, that&#39;s impossible) in 2015.</p>
]]></content:encoded></item><item><title>VATMOSS: the misunderstanding of &quot;proof&quot;</title><guid isPermaLink="false">vatmoss-proof</guid><link>http://remysharp.com/2014/12/30/vatmoss-proof</link><pubDate>Tue, 30 Dec 2014 12:00:00 +0000</pubDate><description><![CDATA[When you apply EU VAT, you need to be sure of your customer&#39;s EU state. Indeed, you&#39;ll be asked for two non-conflicting pieces of proof. I&#39;m unsure if this is a VATMOSS thing or EU VAT, but it doesn&#39;t really matter.
There was a recent clarification allowing companies to use one of five presumptions for choosing location of residency, but when I asked Rachel Andrew&#39;s opinion of the first draft of this post, she pointed out that the presumptions are for fixed lined services only (referring to notes that I can&#39;t see), but she&#39;s right.]]></description><content:encoded><![CDATA[
<p>When you apply EU VAT, you need to be sure of your customer&#39;s EU state. Indeed, you&#39;ll be asked for <strong>two non-conflicting pieces of proof</strong>. I&#39;m unsure if this is a VATMOSS thing or EU VAT, but it doesn&#39;t really matter.</p>
<p>There was a recent clarification allowing companies to use one of <a href="http://www.vatlive.com/eu-vat-rules/2015-digital-services-moss/location-of-customer-moss-2015/">five presumptions for choosing location of residency</a>, but when I asked Rachel Andrew&#39;s opinion of the first draft of this post, she pointed out that the presumptions are for <em>fixed lined services</em> only (referring to notes that I can&#39;t see), but she&#39;s right.</p>
<p>These presumptions are utterly useless to any normal small business running a web site. In fact, I&#39;d argue that any service that can ascertain whether their customer is connected using a fixed land line or a mobile network (i.e. an ISP, Telecom provider or broadcaster) is not &quot;mini&quot; enough for a Mini One Stop Shop.</p>
<h2>2 non-conflicting pieces of location data</h2>
<p>The proof required for any web site selling digital products or services is 2 pieces of data, but if these are in conflict (i.e. the country doesn&#39;t match up) then you&#39;ll need a 3rd.</p>
<p>This is actually a bit of joke, because if the 3rd is also in conflict, you need another until you do actually have two items of data that resolves to a single country.</p>
<p>The suggestions of what this can be are actually a bit wishy-washy. You&#39;re fine if your first 2 items match, but getting a 3rd is the problem.</p>
<p>Here are the suggestions from HMRC:</p>
<blockquote>
<p>Any two pieces of non-contradictory evidence such as, IP address, bank account address or SIM card identifier code will suffice. – @HMRCcustomers</p>
</blockquote>
<p><em><a href="https://twitter.com/HMRCcustomers/status/537996346838761472">Source: Twitter, November 27, 2014</a></em></p>
<p>This has been further clarified by others to this list (which you&#39;ll see most posts suggesting):</p>
<p>Let&#39;s separate this list into what we can feasibly collect before the transaction occurs.</p>
<h3>Available before</h3>
<ul>
<li>The billing address of the customer</li>
<li>The Internet Protocol (IP) address of the device used by the customer</li>
<li>Other commercially relevant information (for example, product coding information which electronically links the sale to a particular jurisdiction)</li>
</ul>
<p>&quot;Other commercially relevant information&quot; is hand-wavy for &quot;anything else&quot;. This is very, <em>very</em> specific to the product type. If your product has some kind of localised version or link to a particular jurisdiction, then great. However, <strong>most services will only have the first two options available</strong>.</p>
<h3>Available after</h3>
<p>That leaves the following available <em>after</em> the customer has completed the transaction (though technically they can be collected before the transaction executes).</p>
<ul>
<li>The country code of SIM card used by the customer</li>
<li>The location of the customer&#39;s fixed land line through which the service is supplied</li>
<li>Location of the bank</li>
</ul>
<p>SIM card is only available if you implement an extra SMS verification process (<a href="https://dashboard.taxamo.com/apidocs/api/v1/verification/docs.html">Taxamo provide this as extra service</a>) - but it&#39;s a rare to have this technology available, plus the technical expertise to implement puts this out of reach for most small businesses.</p>
<p>Knowledge of the customer&#39;s fixed land line will <em>never</em> be available to web sites (again, this is fixed line services as mentioned at the start of this post).</p>
<p>So we&#39;re left with &quot;location of the bank&quot;. I believe <strong>if you have the bank location, you shouldn&#39;t need anything else</strong>.</p>
<h2>Example case study</h2>
<p>Jane living in the UK, working for Italian company Air Italy (the airline) as a developer and she needs a subscription to my product.</p>
<p>My product is going to get for 3 pieces of information on purchase of my product:</p>
<ol>
<li>The billing address of the debit or credit card used</li>
<li>Her IP address run against a geoip lookup database (ie. to best guess her location)</li>
<li>The telephone landline number (using the country code from the phone number)</li>
</ol>
<p>As the address the web site asks for, she puts the company head office address (she&#39;s guessing and assuming that this is actually the billing address, but she&#39;s unsure), her company uses a VPN to access the internet through their ISP and the landline number is +44...</p>
<p>The result is:</p>
<ol>
<li>The billing address resolves to Italy</li>
<li>IP address resolves to Switerland (equally Jane could be travelling)</li>
<li>The phone number resolves to the UK</li>
</ol>
<p>However, as she pays she has <em>two</em> options:</p>
<ol>
<li>Use her personal bank card</li>
<li>Use the business bank card</li>
</ol>
<p>If she uses her personal bank card, the country location is UK, and the money she has in her UK bank account is taxed under UK tax law.</p>
<p>If she uses her business bard card, then country location it Italy, and the money (in that bank account) is correctly taxed under Italian tax law.</p>
<p>Making the initial 3 pieces of information utterly redundant, and the card country origin the ultimate source of truth.</p>
<h2>The ultimate source of truth</h2>
<p>Some businesses won&#39;t be able to get the card holder bank origin before actually applying the correct VAT. In this case, then you have to make the assumption based on the non-conflicting data.</p>
<p>However, if you&#39;re using a system like Stripe (as I am), then you get full details about the card data <strong>before</strong> you finalise the transaction cost.</p>
<p>If the bank that holds the card is based Italy (for instance) then the individual who opened the account must provide proof of citizenship to their Italian bank or if it was opened by a business, then the business must legally operate in that country.</p>
<p>Both of these facts require that the individual or business pay taxes in Italy, and <strong>therefore if the card says it&#39;s registered in Italy, there&#39;s no other option that to charge them Italian VAT rates</strong>.</p>
<p>Therefore: if you have the card country origin, you <strong>don&#39;t need anything else</strong>.</p>
<hr>
<p>I&#39;ve no idea how, but I&#39;d love to see this proposed to the HMRC and HM Treasury groups that are discussing these problems behind closed doors.</p>
]]></content:encoded></item><item><title>VATMOSS</title><guid isPermaLink="false">vatmoss</guid><link>http://remysharp.com/2014/12/16/vatmoss</link><pubDate>Tue, 16 Dec 2014 11:00:00 +0000</pubDate><description><![CDATA[If you want a good foundation of understand for VATMOSS, then I highly recommend reading Rachel Andrew&#39;s posts.
That said, having read as much as I can around the web, I still don&#39;t feel like I have a good handle on this thing, but I&#39;m posting this, partly to flesh out my thoughts, help others in the same situation, and probably rant.
We have to be VATMOSS ready by 1-Jan 2015. That&#39;s just over 2 weeks away.]]></description><content:encoded><![CDATA[
<p>If you want a good foundation of understand for VATMOSS, then I highly recommend reading <a href="http://rachelandrew.co.uk/archives/tag/vat">Rachel Andrew&#39;s posts</a>.</p>
<p>That said, having read as much as I can around the web, I still don&#39;t feel like I have a good handle on this thing, but I&#39;m posting this, partly to flesh out my thoughts, help others in the same situation, and probably rant.</p>
<p>We have to be VATMOSS ready by 1-Jan 2015. That&#39;s just over 2 weeks away.</p>
<p><em>Please note: this is barely edited, and feels a bit &#39;scare-monger-y&#39; (sorry) and I would <strong>strongly encourage comments</strong>, corrections, updates, etc in the comments.</em></p>
<h2>What is VATMOSS</h2>
<p>In my own words, and my layman understanding:</p>
<p>Being in the UK and VAT registered, today I need to charge 20% VAT to all non VAT registered EU customers. Outside the EU, there&#39;s no VAT applied. If the customer is VAT registered, then I don&#39;t apply VAT.</p>
<p>This changes with VATMOSS, but only for those EU customers. Instead of charging UK 20% VAT, I must charge the individual their local VAT. So if the customer is German, I charge them 19% VAT.</p>
<p><strong>This logic will apply to all businesses running in the EU.</strong></p>
<h2>Technical considerations</h2>
<p>There&#39;s a list of important technical items I need to check off to make sure I&#39;m compliant:</p>
<ul>
<li>Collect <em>two</em> pieces of non-conflicting information that proves which EU member state the customer is in. This can be IP address (with country lookup), or bank country, or address, and so on. I believe Stripe has all this information for me and I don&#39;t need to collect anything extra.</li>
<li>I need an up to date list of all the VAT rates for EU states. <a href="http://jsonvat.com">http://jsonvat.com</a> is a good example of what I need, but it&#39;s maintained by an individual so I intend to use a copy of the file, and try, somehow, to manually stay on top of live updates via <a href="http://www.vatlive.com/vat-rates/european-vat-rates/eu-vat-rates/">VAT live</a>. Far from ideal.</li>
<li>Since I have users that are subscribed to a subscription model, I need to shift them all off the existing 20% fixed VAT subscription and move them to the new system of dynamic VAT rates (and I&#39;ll email all those individuals to attempt to explain).</li>
<li>I&#39;m using <a href="https://stripe.com">Stripe</a> for payment processing, so we&#39;re having to upgrade with the following logic:<ol>
<li>Add an addition invoice item to their initial subscription that adds VAT.</li>
<li>When the <code>invoice.created</code> webhook comes in, only if the <code>data.paid</code> is <code>false</code> then add the VAT as an addition invoice item.</li>
</ol>
</li>
</ul>
<h2>Issues</h2>
<ol>
<li>I don&#39;t see any way to retrospectively ask my existing subscriptions for more information about their sign up. It&#39;s technically possibly that I capture their IP address in our application logs, and manually add them to our Stripe customers, but that&#39;s a messy process.</li>
<li>I read that the invoices have to adhere to the county&#39;s regulations. I&#39;ve no idea what that is for all the countries. It was hard enough finding a list of the rates, let alone the invoice requirements.</li>
<li>We don&#39;t currently send out any emails from JS Bin on subscription renewal - I suspect that&#39;s a weak spot and we&#39;ll need to implement that.</li>
<li>A way to report for the EU MOSS return...sigh.</li>
</ol>
<p>My biggest issue, and the one that&#39;s actually killing business in the UK, is the admin overhead of this change outweighs the benefits.</p>
<p>I&#39;ve considered blocking EU members from subscribing (and therefore unsubscribing existing EU customers), but some &quot;legislation (eg anti discrimination) may apply&quot;.</p>
<p>I&#39;ve considered just killing the business side of JS Bin because this whole process is so disheartening.</p>
<p>I&#39;ve joked about charging a flat 27% VAT (as this is the highest) and intentionally reporting the wrong TAX to the VAT office. Historically if they owe you money, the VAT office is horrible to work with (whereas if you owe them money, they&#39;re particularly efficient), so maybe this is a clean simple &quot;solution&quot;.</p>
<p>I&#39;ve looked at <a href="http://quaderno.io">Quaderno</a> and <a href="http://www.taxamo.com/">Taxamo</a>, but the technical implementation isn&#39;t our issue - it&#39;s the business admin. I&#39;m also wary of changing our existing UX for the upgrade process, asking for a tonne more information seems overkill and unnecessary, and only required to satisfy these over the top legislations.</p>
<h2>In closing</h2>
<p>VATMOSS is a total mess. It&#39;s even more concerning that the details haven&#39;t <a href="https://www.enterprisenation.com/blog/posts/exclusive-hmrc-update-on-vat-moss">even been fleshed</a> out yet with 2 weeks to go (notice the post says they&#39;re going to post detailed guidance...).</p>
<p>I&#39;m reviewing Quaderno right now, but the more I look the more I feel like our bespoke solution is the right way to go.</p>
<p>However, this does leave a very sour taste in my mouth for running more business online, and it&#39;s further support that the UK government does not care anywhere near as much as it should, about entrepreneurship in the UK.</p>
<p>This legislation is killing business in the UK.</p>
]]></content:encoded></item><item><title>To You</title><guid isPermaLink="false">to-you</guid><link>http://remysharp.com/2014/12/06/to-you</link><pubDate>Sat, 06 Dec 2014 9:00:00 +0000</pubDate><description><![CDATA[This makes my final post on The Pastry Box. Though its only been six posts, its felt like something different. Indeed early on I realised it was somewhere different that I could experiment with content.
Due to what was going on in my life at the time, the posts quickly became very personal, and I felt comfortable enough to share some of my darker thoughts. That hasn&#39;t gone away, and people have been remarkably kind in their response. I hope to be strong enough to bring this directly to my own blog (though of course all my content is cross posted to my own blog).
For my final post I wanted to end on something I&#39;ve been wanting to write about for years. In fact, I started writing a version of this post in 2008, but the text was long lost.
I wanted to acknowledge my wife, best friend, mother of my children and partner in all things: Julie.
We have a few anniversaries that we keep, but today, the 6th December would mark the day that we started &quot;going out&quot;, dating, courting, whatever you&#39;d like to call it, 18 years ago.
18 years marks a special year too, we&#39;ve now been together longer in our lives than the time that we&#39;ve not been together. Our halfway mark. I&#39;m pretty damn proud to be her husband.
Julie&#39;s responsible for all kinds of huge things throughout my life, and has even positively impacted the web community that I work inside of.
Let me indulge in some history
We got together back in 6th form (when we were just 18 in 1996), and both failed to get into our first choice universities. We had expected to separate our fledgling romance when we headed off, but as fate would have it, we were to go to the same university: Kingston upon Thames.
We&#39;d spend the next few years joined at the hip. Spending all hours of the days together - often me bunking off my classes to hang out with her.
Then it all changed when I landed a sandwich year work placement - we went from spending 247 together, to me spending pretty much 9 &#39;til 9 with my boss and very little time with Julie.
That didn&#39;t stop us. Julie supported me, in amazing ways. It was pretty much a long distance relationship whilst living together.
But it wasn&#39;t all work. We&#39;d spend uncountable nights getting drunk and being silly together. Watching movies together and staying up late to watch just one more episode of 24.
Of course I wanted to marry my best friend. I proposed, at a carefully planned sunset on the beach on a chilly January back in 2001. Her words (in an urgent unknowing): &quot;Urm, uh, uh, I don&#39;t know...um...yes? I guess?!&quot;.
We&#39;d marry in 2004. We&#39;d spend 3 months in Whistler on sabbatical together. We&#39;d move to Brighton. We&#39;d do regular bank holiday super-epic pub crawls. We&#39;d buy a house.
We&#39;d go through the most terrible thing, and we&#39;d survive. Together.
And now...
And now we have Ellis and Seren, and somehow our family is complete in spite of losing Tia, she&#39;s part of that family too.
For some reason I was lucky enough to find the person that makes me whole from such a young age, and some 18 years later Julie&#39;s still my best friend and the person whose life I always want to share.
To Julie: I love you. Always. From the days that we were kids to the days when we&#39;re old and grey.

Reposted from The Pastry Box Project]]></description><content:encoded><![CDATA[
<p>This makes my final post on The Pastry Box. Though its only been six posts, its felt like something different. Indeed early on I realised it was somewhere different that I could experiment with content.</p>
<p>Due to what was going on in my life at the time, the posts quickly became very personal, and I felt comfortable enough to share some of my darker thoughts. That hasn&#39;t gone away, and people have been remarkably kind in their response. I hope to be strong enough to bring this directly to my own blog (though of course all my content is cross posted to my own blog).</p>
<p>For my final post I wanted to end on something I&#39;ve been wanting to write about for years. In fact, I started writing a version of this post in 2008, but the text was long lost.</p>
<p>I wanted to acknowledge my wife, best friend, mother of my children and partner in all things: Julie.</p>
<p>We have a few anniversaries that we keep, but today, the 6th December would mark the day that we started &quot;going out&quot;, dating, courting, whatever you&#39;d like to call it, 18 years ago.</p>
<p>18 years marks a special year too, we&#39;ve now been together longer in our lives than the time that we&#39;ve not been together. Our halfway mark. I&#39;m pretty damn proud to be her husband.</p>
<p>Julie&#39;s responsible for all kinds of huge things throughout my life, and has even positively impacted the web community that I work inside of.</p>
<h2>Let me indulge in some history</h2>
<p>We got together back in 6th form (when we were just 18 in 1996), and <em>both failed</em> to get into our first choice universities. We had expected to separate our fledgling romance when we headed off, but as fate would have it, we were to go to the same university: Kingston upon Thames.</p>
<p>We&#39;d spend the next few years joined at the hip. Spending all hours of the days together - often me bunking off my classes to hang out with her.</p>
<p>Then it all changed when I landed a sandwich year work placement - we went from spending 247 together, to me spending pretty much 9 &#39;til 9 with my boss and very little time with Julie.</p>
<p>That didn&#39;t stop us. Julie supported me, in amazing ways. It was pretty much a long distance relationship whilst living together.</p>
<p>But it wasn&#39;t all work. We&#39;d spend uncountable nights getting drunk and being silly together. Watching movies together and staying up late to watch <em>just one more</em> episode of 24.</p>
<p>Of course I wanted to marry my best friend. I proposed, at a carefully planned sunset on the beach on a chilly January back in 2001. Her words (in an urgent unknowing): &quot;Urm, uh, uh, I don&#39;t know...um...yes? I guess?!&quot;.</p>
<p>We&#39;d marry in 2004. We&#39;d spend 3 months in Whistler on sabbatical together. We&#39;d move to Brighton. We&#39;d do regular bank holiday super-epic pub crawls. We&#39;d buy a house.</p>
<p>We&#39;d go through the most terrible thing, and we&#39;d survive. Together.</p>
<h2>And now...</h2>
<p>And now we have Ellis and Seren, and <em>somehow</em> our family is complete in spite of losing Tia, she&#39;s part of that family too.</p>
<p>For some reason I was lucky enough to find the person that makes me whole from such a young age, and some 18 years later Julie&#39;s <em>still</em> my best friend and the person whose life I always want to share.</p>
<p>To Julie: I love you. Always. From the days that we were kids to the days when we&#39;re old and grey.</p>
<p><img src="/images/us-1996.jpg" alt="Remy &amp; Julie"></p>
<p>Reposted from <a href="https://the-pastry-box-project.net/remy-sharp/2014-december-6">The Pastry Box Project</a></p>
]]></content:encoded></item><item><title>Makefile instead of hoop jumping</title><guid isPermaLink="false">makefile</guid><link>http://remysharp.com/2014/12/02/makefile</link><pubDate>Tue, 02 Dec 2014 10:00:00 +0000</pubDate><description><![CDATA[In 2012 I ran a Build Process workshop as part of ffconf tooling tutorials. Early on as part of my workshop introduction I said that makefiles were hard and for harden unix beared folk...or something. Grunt (and the like) were definitely a gentler solution.
I still stand by that, but today the idea of installing a bunch of dependancies just so I can have my Less file converted to CSS in real-time feels...well, crap.]]></description><content:encoded><![CDATA[
<p>In 2012 I ran a Build Process workshop as part of <a href="http://2012.ffconf.org/#tooling">ffconf tooling tutorials</a>. Early on as part of my workshop introduction I said that makefiles were hard and for harden unix beared folk...or something. Grunt (and the like) were definitely a gentler solution.</p>
<p>I still stand by that, but today the idea of installing a bunch of dependancies <em>just</em> so I can have my Less file converted to CSS in real-time feels...well, crap.</p>
<h2>Barebones</h2>
<p>When I write my JavaScript, I err on the side of barebones. I tend to roll without libraries and frameworks, and (for better or worse) I don&#39;t use frameworks like Ember or Angular.</p>
<p>I prefer lean and close to the metal. Obviously I&#39;ll employ a framework when I&#39;m repeating myself over and over, but this has always been my preference when developing.</p>
<p>When I think of it like that, it makes sense that I&#39;d eventually end up wanting to use low levels tools like Make to handle my workflow (and eventually build process).</p>
<h2>My requirements</h2>
<p>I had a project that used Less to generate the CSS. Originally we had an Express middleware that would generate the CSS file on demand.</p>
<p>The result was the was a significant flash of unstyled content whilst the initial build of the CSS ran (perhaps on each release - I don&#39;t recall). So we changed it so that CSS would build once.</p>
<p>Now when we changed the <code>.less</code> file, we had to re-run the build...</p>
<p>I moaned (as usual) on twitter, and got lots of useful responses, but it mostly involved installing mutliple tools (Grunt or Gulp, plus some 3rd party lib to generate, then the watcher...etc) or suggestions that changed the workflow I was using.</p>
<p>This doesn&#39;t sit well. My requirements (to me) were simple:</p>
<ol>
<li>When a single <code>.less</code> file changes</li>
<li>Rebuild it</li>
<li>Repeat</li>
</ol>
<p>Simple.</p>
<h2>Solution</h2>
<p>There&#39;s two parts, and the execution.</p>
<ol>
<li>Watch: when a watched file changes run a command</li>
<li>Rebuild only the file that changed</li>
</ol>
<p>The execution is simple, in my <code>package.json</code> file (because I&#39;m using npm &amp; node), I have:</p>
<pre><code class="language-json">{
  &quot;scripts&quot;: {
    &quot;watch&quot;: &quot;&lt;command&gt;&quot;
  }
}</code></pre>
<p>And on the command line I run:</p>
<pre><code class="language-shell">$ npm run watch</code></pre>
<h3>Watch</h3>
<p>I looked into <a href="http://npmjs.org/gaze">gaze</a>, <a href="https://github.com/caseywebdev/watchy">watchy</a> and a few others, but eventually settled on two potentials:</p>
<ul>
<li><a href="https://github.com/emcrisostomo/fswatch">fswatch</a> - which is mac specific</li>
<li><a href="https://github.com/remy/nodemon">nodemon</a> - my own creation, but actually works perfectly</li>
</ul>
<p>Here&#39;s how the watch works with <code>fswatch</code>:</p>
<pre><code class="language-shell">fswatch -o public/css/*.less | xargs -n1 -I{} make</code></pre>
<p>And the same thing with nodemon (via a locally installed <code>npm install -g nodemon</code>):</p>
<pre><code class="language-shell">nodemon --quiet --watch public/css/ --ext css --exec make
# same thing except with shorthand flags:
# nodemon -q -w public/css/ -e css -x make</code></pre>
<p>Now whenever a .less file changes in the <code>public/css</code> directory, my <code>make</code> command runs, and because Make is clever, it&#39;ll only recompile the files that have actually changed.</p>
<p>Aside: In my own projects, I&#39;ve gone further with nodemon, to use it for automatically re-running tests and recompiling JavaScript for development.</p>
<h3>Rebuild</h3>
<p>Make is clever in that it will only rebuild the files whose dependencies have changed. In that the <code>.css</code> file has a <code>.less</code> file dependency, so when that&#39;s changed, make will run the command to rebuild our individual <code>.css</code> file.</p>
<pre><code class="language-makefile"># when you run `make` alone, run the `css` rule (at the
# bottom of this makefile)
all: css

# .PHONY is a special command, that allows you not to
# require physical files as the target (allowing us to
# use the `all` rule as the default target).
.PHONY: all

# replace all .less files with .css extension and cache
# the results in a variable called `css_files`
css_files := $(patsubst %.less, %.css, $(wildcard ./public/css/*.less))

# when a .css file is *not* up to date compared to the
# .less file, then make will run the the following commands:
# - echo the string &quot;foo.less -&gt; foo.css&quot;
# - run the command `lessc -x --source-map foo.less foo.css`
./public/css/%.css: public/css/%.less
  @echo &quot;$&lt; -&gt; $@&quot;
  @./node_modules/.bin/lessc -x --source-map $&lt; $@

css: $(css_files)</code></pre>
<h2>Final result</h2>
<p>The <a href="https://gist.github.com/remy/274232f8b47dfa163324">final result</a> is pretty awesome, especially with CSS source maps enabled in devtools.</p>
<p>I can edit and change the Less file in devtools, and the rebuild is near instant, which in turn is detected by devtools, which is then injected into Chrome so I see the updates happening in near-real-time:</p>
<iframe width="1280" height="720" src="//www.youtube.com/embed/6bcCpk_U3qc?rel=0" frameborder="0" allowfullscreen></iframe>

<p>As further reading, I highly recommend you check out <a href="https://blog.jcoglan.com/2014/02/05/building-javascript-projects-with-make/">James Coglan&#39;s excellent post on using Make</a> for a full JavaScript project.</p>
]]></content:encoded></item><item><title>My five promise patterns</title><guid isPermaLink="false">my-five-promise-patterns</guid><link>http://remysharp.com/2014/11/19/my-five-promise-patterns</link><pubDate>Wed, 19 Nov 2014 12:00:00 +0000</pubDate><description><![CDATA[I&#39;ve been getting big into promises over the last year. I think the two best resources that I&#39;ve learnt from today is Forbes Lindesay&#39;s talk at JSConf.EU 2013 and Jake Archibald&#39;s excellent promise article on html5rocks.
There&#39;s been some patterns that I use over and over so I wanted to share and document them.
Please note that the examples used are mostly based on my real code, but have been simplified for demonstration purposes.


Library of choice
Firstly I prefer to use the native implementation, and go bare bones. I&#39;m sure they will be a time that I&#39;ll want more than the native API has to offer, but I&#39;ve not arrived there yet.
As a client side polyfill and the server side, in node-land, since promises are oddly not available natively, my preferred library is then/promise.
I&#39;ve used RSVP in the past and heard decent things about Bluebird.
RSVP feels like it&#39;s mostly bare bones, but I learnt about promise.js&#39; denodeify which converts a callback based function into a promise function which can be very useful.
Update @ 2014-11-19 15:30:00 RSVP does also have denodeify and Matt Andrews of The FT has released a stand alone denodeify module.
Clean shallow chains
This means my initial promise code would look like:
writeFile(filename, content)
  .then(addDBUser)
  .then(dns)
  .then(configureHeroku)
  .then(function () {
    console.log(&#39;All done&#39;);
  })
This is easy if these are all my functions, but I can also do this with third party libraries via denodeify (a feature of the promise.js library, though most promise libraries have something similar) – turn a callback pattern function into a promise based function:
var writeFile = Promise.denodeify(fs.writeFile):

writeFile(filename, content)
  .then(addDBUser)
Though one place I&#39;ve been caught out with denodeify is when the method relies on method&#39;s context, which is most things as it turns out (fs is just a fluke that it&#39;s methods don&#39;t rely on the context), so make sure to bind as required:
var addUser = Promise
  .denodeify(model.user.add)
  .bind(model.user) // multi line for blog readability
Prebaking
You&#39;ve already seen that I use bind, but I&#39;ve also found that in some situations, I need to call a function with static arguments (i.e. not relying on the previous promise), just because it&#39;s part of the promise chain.
I could do this:
writeFile(filename, content)
  .then(function () {
    return addUserToDb(&#39;rem&#39;, &#39;password&#39;, &#39;some-db&#39;);
  })
Or, what I&#39;ve found I&#39;m more inclined to do now is prebake the addUserToDb call with the static arguments:
var addUser = addUserToDb.bind(null, &#39;rem&#39;,
      &#39;password&#39;, &#39;some-db&#39;);

writeFile(filename, content)
  .then(addUser)
This also allows me to code with the shallow chains as above, because it (to me) feels a bit verbose to drop into a function just to return a promise straight back out that doesn&#39;t depend on any unknown variable.
The thing to watch out for is if the function behaves differently if there&#39;s more arguments, I have to cold call the promise.
Cold calling
Disclaimer: this patterned is required due to my own prebaking patterns and attempts to (ironically) simplify. There&#39;s a good chance you won&#39;t need this!
When a function works both as a promise and using the callback pattern - it&#39;s great, but I&#39;ve been caught out in the past.
The way the function might work under the hood is something like (this pseudo code):
Heroku.prototype.post = function (slug, options, callback) {
  // do some async thing
  this.request(slug, options, function (error, data) {

    // ** this line is how the dual functionality works ** //
    if (callback) callback(error, data);

    // else do something with promise
  });

  // return some promise created some place
  return this.promise;
}
So post can be called either as a promise:
heroku.post(slug, opts).then(dostuff);
Or as a callback:
heroku.post(slug, opts, dostuff);
But gets messy when you do this:
function configureHeroku(slug) {
  // prebake heroku app create promise
  var create = heroku.post.bind(heroku,
    &#39;/apps&#39;,
    { name: &#39;example-&#39; + slug }
  );

  // prebake domain config
  var domain = heroku.post.bind(heroku,
    &#39;/apps/example-&#39; + slug + &#39;/domains&#39;,
    { hostname: slug + &#39;.example.com&#39; }
  );

  // ** this is where it goes wrong ** //
  return create().then(domain);
}
The issue is when domain is called, it&#39;s actually called with the prebaked arguments of the slug and options but also the resolved value from create() - so a third argument is received.
This third argument is the resolved result of create() which is treated as the callback argument and as a function object, so the code will try to invoke it - causing an exception.
My solution is to wrap in a cold call - i.e. a newly created function that calls my method with no arguments. Like bind once but then never allow any new arguments, also known as currying (here&#39;s a simple demo of the curry/partial/seal type-thing):
function coldcall(fn) {
  return function () {
    fn();
  };
}

function configureHeroku(slug) {
  // prebake heroku app create promise
  // ...


  // ** now it works ** //
  return create().then(coldcall(domain));
}
Note: you can do this using currying, i.e. lodash.curry.
Now the domain call works because it&#39;s invoked preventing any extra arguments being added.
Throw over explicit reject
Instead of:
// compare password &amp; input password
return new Promise(function (resolve, reject) {
  bcrypt.compare(input, password, function (error, result) {
    if (error || !result) {
      // reject and early exit
      return reject(error);
    }

    resolve(result);
  });
});
I&#39;ll throw instead of reject:
// compare password &amp; input password
return new Promise(function (resolve) {
  bcrypt.compare(input, password, function (error, result) {
    if (error) {
      throw error;
    }

    if (!result) {
      throw new Error(&#39;Passwords did not match.&#39;);
    }

    resolve(result);
  });
});
This might be a little controversial. In fact, when I threw this out to twitter, most people came back with something like:

Reject whenever possible, it&#39;s more performant because throw breaks the stack.

This may well be so, but there&#39;s a few key benefits to my code when I throw:

I&#39;m used to error first handling, and quite often I&#39;ll accidently recieve reject as the first argument, which leads to much confusion. This way, I only ever accept resolve as my argument. There&#39;s also issues where &quot;reject&quot; and &quot;resolve&quot; as words are visually similar, which has also lead to confusion when they&#39;re the wrong way around!
I don&#39;t have to remember to return reject. I&#39;ve seen code that doesn&#39;t return on reject, and it then goes on to resolve with a value. Some libraries fulfill, some reject, some throw new errors. Throwing the error avoids this entirely.
This is also consistent with the way I&#39;ll deal with errors inside of subsequent then calls:

// compare password &amp; input password
utils.compare(input, password)
  .then(function () {
    if (!validUsername(username)) {
      throw new Error(&#39;Username is not valid&#39;);
    }
    // continues...
  })
  .then(etc)
Jake also chimed in with a couple of useful replies:

reject is supposed to be analogous to throw but async. So reject what you&#39;d throw (which is usually an error)

Then linked to his post with &quot;in ES7 async functions reject is throw&quot;. This also reinforces that you want to reject with a real error, not a string.
Always end with a catch
It&#39;s not uncommon for me to be testing a http request with a promise, and it just never returns...
The issue is that the promise has been rejected somewhere and it&#39;s not been caught. So I always end with a catch. Even if it&#39;s a dump to the console, that way I know something failed.
writeFile(filename, content)
  .then(addDBUser)
  .then(dns)
  .then(configureHeroku)
  .then(function () {
    console.log(&#39;All done&#39;);
  })
  .catch(function (error) {
    // do something with error
    console.log(error.stack);
    handle(error);
  });
This final catch lets me see the full stacktrace as to what went wrong, and importantly that something did go wrong (see blog comments for discussion about this).
Note: .catch() is only in the ES6 spec and doesn&#39;t appear in Promises/A+ so some library implementations are missing .catch() support (as I&#39;ve found with mongoose as it depends on mPromise library).
Recap
So that&#39;s it:

Shallow chains
Prebaking where I can and cold calling if neccessary
Always throw
Always catch

Pretty simple. I&#39;d be interested to hear what patterns are emerging in your workflow too.]]></description><content:encoded><![CDATA[
<p>I&#39;ve been getting big into promises over the last year. I think the two best resources that I&#39;ve learnt from today is Forbes Lindesay&#39;s <a href="https://www.youtube.com/watch?v=qbKWsbJ76-s">talk at JSConf.EU 2013</a> and Jake Archibald&#39;s excellent <a href="http://www.html5rocks.com/en/tutorials/es6/promises/">promise article on html5rocks</a>.</p>
<p>There&#39;s been some patterns that I use over and over so I wanted to share and document them.</p>
<p><em>Please note that the examples used are </em>mostly<em> based on my real code, but have been simplified for demonstration purposes.</em></p>
<!-- more -->

<h2>Library of choice</h2>
<p>Firstly I prefer to use the native implementation, and go bare bones. I&#39;m sure they will be a time that I&#39;ll want more than the native API has to offer, but I&#39;ve not arrived there yet.</p>
<p>As a client side polyfill and the server side, in node-land, since promises are oddly not available natively, <strong>my preferred library is <a href="https://github.com/then/promise">then/promise</a></strong>.</p>
<p>I&#39;ve used <a href="https://github.com/tildeio/rsvp.js">RSVP</a> in the past and heard decent things about <a href="https://github.com/petkaantonov/bluebird">Bluebird</a>.</p>
<p>RSVP feels like it&#39;s mostly bare bones, but I learnt about promise.js&#39; <code>denodeify</code> which converts a callback based function into a promise function which can be very useful.</p>
<p><em>Update @ 2014-11-19 15:30:00</em> RSVP does also have <a href="https://github.com/tildeio/rsvp.js/blob/master/lib/rsvp/node.js#L74">denodeify</a> and Matt Andrews of The FT has released a <a href="https://www.npmjs.org/package/denodeify">stand alone denodeify</a> module.</p>
<h2>Clean shallow chains</h2>
<p>This means my initial promise code would look like:</p>
<pre><code class="language-js">writeFile(filename, content)
  .then(addDBUser)
  .then(dns)
  .then(configureHeroku)
  .then(function () {
    console.log(&#39;All done&#39;);
  })</code></pre>
<p>This is easy if these are all my functions, but I can also do this with third party libraries via <code>denodeify</code> (a feature of the promise.js library, though most promise libraries have something similar) – turn a callback pattern function into a promise based function:</p>
<pre><code class="language-js">var writeFile = Promise.denodeify(fs.writeFile):

writeFile(filename, content)
  .then(addDBUser)</code></pre>
<p>Though one place I&#39;ve been caught out with <code>denodeify</code> is when the method relies on method&#39;s context, which is most things as it turns out (<code>fs</code> is just a fluke that it&#39;s methods don&#39;t rely on the context), so make sure to <code>bind</code> as required:</p>
<pre><code class="language-js">var addUser = Promise
  .denodeify(model.user.add)
  .bind(model.user) // multi line for blog readability</code></pre>
<h2>Prebaking</h2>
<p>You&#39;ve already seen that I use <code>bind</code>, but I&#39;ve also found that in some situations, I need to call a function with static arguments (i.e. not relying on the previous promise), just because it&#39;s part of the promise chain.</p>
<p>I <em>could</em> do this:</p>
<pre><code class="language-js">writeFile(filename, content)
  .then(function () {
    return addUserToDb(&#39;rem&#39;, &#39;password&#39;, &#39;some-db&#39;);
  })</code></pre>
<p>Or, what I&#39;ve found I&#39;m more inclined to do now is prebake the <code>addUserToDb</code> call with the static arguments:</p>
<pre><code class="language-js">var addUser = addUserToDb.bind(null, &#39;rem&#39;,
      &#39;password&#39;, &#39;some-db&#39;);

writeFile(filename, content)
  .then(addUser)</code></pre>
<p>This also allows me to code with the <a href="#clean-shallow-chains">shallow chains</a> as above, because it (to me) feels a bit verbose to drop into a function just to return a promise straight back out that doesn&#39;t depend on any unknown variable.</p>
<p>The thing to watch out for is if the function behaves differently if there&#39;s more arguments, I have to cold call the promise.</p>
<h2>Cold calling</h2>
<p><strong><em>Disclaimer:</em></strong> <em>this patterned is required due to my own prebaking patterns and attempts to (ironically) simplify. There&#39;s a good chance you won&#39;t need this!</em></p>
<p>When a function works both as a promise <em>and</em> using the callback pattern - it&#39;s great, but I&#39;ve been caught out in the past.</p>
<p>The way the function might work under the hood is something like (this pseudo code):</p>
<pre><code class="language-js">Heroku.prototype.post = function (slug, options, callback) {
  // do some async thing
  this.request(slug, options, function (error, data) {

    // ** this line is how the dual functionality works ** //
    if (callback) callback(error, data);

    // else do something with promise
  });

  // return some promise created some place
  return this.promise;
}</code></pre>
<p>So <code>post</code> can be called either as a promise:</p>
<pre><code class="language-js">heroku.post(slug, opts).then(dostuff);</code></pre>
<p>Or as a callback:</p>
<pre><code class="language-js">heroku.post(slug, opts, dostuff);</code></pre>
<p>But gets messy when you do this:</p>
<pre><code class="language-js">function configureHeroku(slug) {
  // prebake heroku app create promise
  var create = heroku.post.bind(heroku,
    &#39;/apps&#39;,
    { name: &#39;example-&#39; + slug }
  );

  // prebake domain config
  var domain = heroku.post.bind(heroku,
    &#39;/apps/example-&#39; + slug + &#39;/domains&#39;,
    { hostname: slug + &#39;.example.com&#39; }
  );

  // ** this is where it goes wrong ** //
  return create().then(domain);
}</code></pre>
<p>The issue is when <code>domain</code> is called, it&#39;s actually called with the prebaked arguments of the slug and options <em>but also</em> the resolved value from <code>create()</code> - so <strong>a third argument is received</strong>.</p>
<p>This third argument is the resolved result of <code>create()</code> which is treated as the <code>callback</code> argument and as a function object, so the code will try to invoke it - causing an exception.</p>
<p>My solution is to wrap in a <em>cold call</em> - i.e. a newly created function that calls my method with no arguments. Like bind once but then never allow any new arguments, also known as currying (here&#39;s a simple demo of the <a href="https://jsbin.com/gopiqu/edit?js,console">curry/partial/seal</a> type-thing):</p>
<pre><code class="language-js">function coldcall(fn) {
  return function () {
    fn();
  };
}

function configureHeroku(slug) {
  // prebake heroku app create promise
  // ...


  // ** now it works ** //
  return create().then(coldcall(domain));
}</code></pre>
<p><em>Note: you can do this using currying, i.e. <a href="https://lodash.com/docs#curry">lodash.curry</a>.</em></p>
<p>Now the <code>domain</code> call works because it&#39;s invoked preventing any extra arguments being added.</p>
<h2>Throw over explicit reject</h2>
<p>Instead of:</p>
<pre><code class="language-js">// compare password &amp; input password
return new Promise(function (resolve, reject) {
  bcrypt.compare(input, password, function (error, result) {
    if (error || !result) {
      // reject and early exit
      return reject(error);
    }

    resolve(result);
  });
});</code></pre>
<p>I&#39;ll throw instead of reject:</p>
<pre><code class="language-js">// compare password &amp; input password
return new Promise(function (resolve) {
  bcrypt.compare(input, password, function (error, result) {
    if (error) {
      throw error;
    }

    if (!result) {
      throw new Error(&#39;Passwords did not match.&#39;);
    }

    resolve(result);
  });
});</code></pre>
<p>This might be a little controversial. In fact, when I threw this out to twitter, most people came back with something like:</p>
<blockquote>
<p>Reject whenever possible, it&#39;s more performant because throw breaks the stack.</p>
</blockquote>
<p>This may well be so, but there&#39;s a few key benefits to my code when I throw:</p>
<ol>
<li>I&#39;m used to error first handling, and quite often I&#39;ll accidently recieve <code>reject</code> as the first argument, which leads to much confusion. This way, I only ever accept <code>resolve</code> as my argument. There&#39;s also issues where &quot;reject&quot; and &quot;resolve&quot; as words are visually similar, which has also lead to confusion when they&#39;re the wrong way around!</li>
<li>I don&#39;t have to remember to <code>return reject</code>. I&#39;ve seen code that doesn&#39;t return on reject, and it then goes on to <code>resolve</code> with a value. Some libraries fulfill, some reject, some throw new errors. Throwing the error avoids this entirely.</li>
<li>This is also consistent with the way I&#39;ll deal with errors inside of subsequent <code>then</code> calls:</li>
</ol>
<pre><code class="language-js">// compare password &amp; input password
utils.compare(input, password)
  .then(function () {
    if (!validUsername(username)) {
      throw new Error(&#39;Username is not valid&#39;);
    }
    // continues...
  })
  .then(etc)</code></pre>
<p>Jake also chimed in with a couple of useful replies:</p>
<blockquote>
<p>reject is supposed to be analogous to throw but async. So reject what you&#39;d throw (which is usually an error)</p>
</blockquote>
<p>Then linked to his <a href="http://jakearchibald.com/2014/es7-async-functions/">post</a> with <em>&quot;in ES7 async functions reject is throw&quot;</em>. This also reinforces that you want to reject with a real error, not a string.</p>
<h2>Always end with a catch</h2>
<p>It&#39;s not uncommon for me to be testing a http request with a promise, and it just never returns...</p>
<p>The issue is that the promise has been rejected somewhere and it&#39;s not been caught. So I <strong>always end with a catch</strong>. Even if it&#39;s a dump to the console, that way I know something failed.</p>
<pre><code class="language-js">writeFile(filename, content)
  .then(addDBUser)
  .then(dns)
  .then(configureHeroku)
  .then(function () {
    console.log(&#39;All done&#39;);
  })
  .catch(function (error) {
    // do something with error
    console.log(error.stack);
    handle(error);
  });</code></pre>
<p>This final catch lets me see the full stacktrace as to what went wrong, and importantly <em>that something did go wrong</em> (see blog comments for discussion about this).</p>
<p><em>Note: <code>.catch()</code> is only in the ES6 spec and doesn&#39;t appear in Promises/A+ so some library implementations are missing <code>.catch()</code> support (as I&#39;ve found with <a href="http://www.mongoosejs.com/">mongoose</a> as it depends on <a href="https://www.npmjs.org/mpromise">mPromise</a> library).</em></p>
<h2>Recap</h2>
<p>So that&#39;s it:</p>
<ul>
<li>Shallow chains</li>
<li>Prebaking where I can and cold calling if neccessary</li>
<li>Always throw</li>
<li>Always catch</li>
</ul>
<p>Pretty simple. I&#39;d be interested to hear what patterns are emerging in your workflow too.</p>
]]></content:encoded></item><item><title>Muddling my way through real time</title><guid isPermaLink="false">muddling-my-way-through-real-time</guid><link>http://remysharp.com/2014/11/10/muddling-my-way-through-real-time</link><pubDate>Mon, 10 Nov 2014 12:30:00 +0000</pubDate><description><![CDATA[If your business deals with data on the web, then that data must be handled in real time, otherwise you&#39;re doing your user a disservice.

Real time demand is a core part of our internet experience, let alone expectation.
Twitter is probably the crowning application of real time I can think of. Hitting the mass audience and industries across the board.
Today we have real time journalism, data, feedback, communication between our teams, from our code and tests. Heck, we can create a brand new virtual machine in under 60 seconds ready to deploy a new site. Back in my day&trade; that process would take 2 weeks!
I recently returned from jsconf.eu 2014, and sitting in the office, only days later I kept catching myself thinking &quot;I&#39;ll just watch the video from jsconf&quot; – but what video? They filmed their events, but somehow I was expecting the event to have already fully edited, titled, uploaded and release all their videos! I know some events that do do this (lxjs for one) – but these aren&#39;t the norm. At what point did I have this (I think) unreasonable expectation on information on the web?
On demand and real time is a normal part of the world we live in today. And if you can&#39;t handle the pressure, your visitor will likely head off elsewhere.

This is my write up of the talk I&#39;ve given on the subject. Slides are also available and the video from SmartWebConf is included below (53mins).]]></description><content:encoded><![CDATA[
<p>If your business deals with data on the web, then that data must be handled in real time, otherwise you&#39;re doing your user a disservice.</p>
<hr>
<p>Real time demand is a core part of our internet experience, let alone expectation.</p>
<p>Twitter is probably the crowning application of real time I can think of. Hitting the mass audience and industries across the board.</p>
<p>Today we have real time journalism, data, feedback, communication between our teams, from our code and tests. Heck, we can create a brand new virtual machine in under 60 seconds ready to deploy a new site. <em>Back in my day</em>&trade; that process would take 2 weeks!</p>
<p>I recently returned from jsconf.eu 2014, and sitting in the office, only days later I kept catching myself thinking &quot;I&#39;ll just watch the video from jsconf&quot; – but what video? They filmed their events, but somehow I was expecting the event to have already fully edited, titled, uploaded and release <em>all</em> their videos! I know some events that do do this (<a href="http://lxjs.org">lxjs</a> for one) – but these aren&#39;t the norm. At what point did I have this (I think) unreasonable expectation on information on the web?</p>
<p><em>On demand</em> and <em>real time</em> is a normal part of the world we live in today. And if you can&#39;t handle the pressure, your visitor will likely head off elsewhere.</p>
<hr>
<p>This is my write up of the talk I&#39;ve given on the subject. <a href="https://speakerdeck.com/rem/muddling-my-way-through-real-time">Slides are also available</a> and the video from SmartWebConf is included below (53mins).</p>
<p><img src="/images/muddling-in-real-time-cover.gif" alt="Muddling your way in real time"></p>
<iframe width="1280" height="720" src="//www.youtube.com/embed/EUnNov3h3c0?index=5&list=PLbUMlIAqtRWNbxKZujb0mO5WHQcwJopBm" frameborder="0" allowfullscreen></iframe>

<hr>
<h2>Contents</h2>
<ol>
<li><a href="#what-is-real-time-to-you">What is real time to you</a></li>
<li><a href="#my-first-introduction-to-real-time-on-the-web">My first introduction to real time on the web</a></li>
<li><a href="#the-origins-of-comet">The origins of Comet</a></li>
<li><a href="#node-is-introduced">Node is introduced</a><ul>
<li><a href="#the-event-loop">The event loop</a></li>
<li><a href="#helloworldjs-of-streaming-servers">helloworld.js of streaming servers</a></li>
</ul>
</li>
<li><a href="#codifying-into-standards">Codifying into standards</a></li>
<li><a href="#so-whats-next">So, what&#39;s next?</a></li>
<li><a href="#core-npm-modules">Core npm modules</a><ul>
<li><a href="#socket-abstraction">Socket abstraction</a></li>
</ul>
</li>
<li><a href="#primus">Primus</a></li>
<li><a href="#scaling">Scaling</a><ul>
<li><a href="#client-side">Client side</a></li>
<li><a href="#server-side">Server side</a></li>
</ul>
</li>
<li><a href="#long-latency-real-time-feedback">Long-latency real time feedback</a></li>
<li><a href="#to-wrap-up">To wrap up</a></li>
</ol>
<h2>What is real time to you?</h2>
<p>I think it&#39;s important to define what <em>I think</em> &quot;real time&quot; means. <a href="http://www.devthought.com/">Guillermo Rauch</a> (creator of Socket.IO) has a <a href="https://www.youtube.com/watch?v=Ar9R-CX217o">few</a> <a href="https://www.youtube.com/watch?v=_8CykecwKhw">excellent</a> talks on the topic, and he describes real time as:</p>
<ul>
<li>Fast</li>
<li>Self-updating</li>
</ul>
<p>I&#39;d go further to say (for me) it needs to be:</p>
<ul>
<li><em>Instant</em></li>
<li>Self-updating</li>
</ul>
<p>I think it&#39;s also important to distinguish between what&#39;s technically real time and what a user perceives as real time. The later being important and the former being arbitrary.</p>
<p>Some applications have been know to respond <em>so</em> quickly that they had to introduce a fake delay to meet their users expectations Specifically: when the program responded so instantly, the user thought something was wrong. With a small delay and a touch of UI feedback (along the lines of &quot;we&#39;ve processing your request&quot;), the user <em>felt</em> the a application was more responsive.</p>
<p>Inversely you might get a push notification to your phone that someone&#39;s mentioned you in a tweet, but when you go to twitter, it can&#39;t connect to update itself. Or <em>you</em> post a tweet and it doesn&#39;t appear in your timeline for ages if you&#39;re on a slow connection. In this case, we want a &quot;self-updating&quot;, and one that can handle errors.</p>
<p>This is my own story of how I discovered the web in real time, what I&#39;ve done over the years and how I use node.js to simplify what used to be very technical problem.</p>
<h2>My first introduction to real time on the web</h2>
<p>My first experience with a real time web was around 2002. I worked for many years on a finance research web site, and stock prices were an important aspect of data.</p>
<p>If you wanted live prices on your site at the time, there would be expensive licences with the London Stock Exchange and some form of Java Applet on your site. We settled for a recurring job that grabbed a 15 minute delayed price CSV file from Yahoo.</p>
<p><img style="width: 40%; display: block; margin: 0 auto;" src="/images/hahabusiness.jpg" title="What it's like to work for the finance sector"></p>
<p>The meant that our prices would be &quot;15 minute delayed&quot; (which was a normal expectation of prices shown on free web sites) but for the subsequent 15 minutes the prices would go stale.</p>
<p>What does that look like?</p>
<pre><code class="language-js">function updatePrices() {
  $.get(&#39;/prices?stock=MSFT&#39;, function (data) {
    renderPrices(data);
    setTimeout(updatePrices, 60 * 1000);
  });
}</code></pre>
<p>Notice that we&#39;re polling using an ajax GET request every minute, in an attempt to get the fresh price when it arrives. The timing looks like this:</p>
<pre><code class="language-nohighlight">09:14 MSFT=$46.68
09:15 ...no change
09:16 ...no change
09:17 ...
09:18 ...
...
09:23 ...
09:24 MSFT=$46.68
09:25 ...no change</code></pre>
<p>It&#39;s also important to realise that all those &quot;no change&quot; requests were wasteful, both because the client is constantly making XHR requests, but the server is also having to deal with requests when the data hasn&#39;t changed at all.</p>
<p>The server is the &quot;ultimate source of truth&quot; and what we want is the <em>server</em> to <em>push</em> the prices to the client.</p>
<hr>
<p>It was one afternoon that one of the data collection team asked me to take a look at one of the finance research sites that they were looking at: Hemscott (I should add the original pages have long since left the web).</p>
<p>The page had a <a href="http://en.wikipedia.org/wiki/Heat_map">heatmap</a> of the FTSE100 prices. What made this particular page interesting is that the prices were changing in real time, and the red/green/sneutral were also changing, so there was a clear visual feedback system to show me this data was live.</p>
<p>What made this page magical though, was I ran the usual &quot;select text test&quot;. i.e. if I can select the text, then it&#39;s &quot;of the web&quot;. If I can&#39;t, it&#39;s Flash or Java Applets (and right clicking would discover which). But this <em>was</em> web. There was a DOM.</p>
<p><img src="/images/hemscott.gif" alt="Hemscott from 2002"></p>
<p><small>(Appologies for the poor picture above: the internet really <em>doesn&#39;t</em> remember!)</small></p>
<p>I spent quite a lot of time poking around some compressed JavaScript, looking at the DOM updating (this was back in the Firebug days so there was no <a href="https://developer.chrome.com/devtools/docs/dom-and-styles#setting-dom-breakpoints">break on DOM subtree modification</a>).</p>
<p>Hemscott had been able to do what we could not: real time prices, using web technology. <strong>It was magic.</strong> That&#39;s all I could ascertain.</p>
<hr>
<p>In retrospect (over several years) I realised that they were achieving the real time effect using Flash. Specifically the <code>XMLSocket</code> to connect to the streaming server and using the &quot;Flash SWF ExternalInterface Bridge&quot; to let JavaScript receive messages from the live stream.</p>
<p>Essentially a very similar technique that&#39;s used in today&#39;s <a href="https://github.com/gimite/web-socket-js">WebSocket polyfill</a> (which uses Flash for the filling part).</p>
<p>In the mean time Google released Google Talk which was the big tipping point in the web&#39;s history for shifting from a request/response pattern, to a server-push pattern, Ajax and Comet respectively.</p>
<h2>The origins of Comet</h2>
<p>Google launched GTalk in 2005 (as part of Gmail) and at the time Google were employing ex-Microsoft developers to solve a very, <em>very</em> specific problem. GTalk used long lived iframes to push the chat events up to the client.</p>
<p>But &quot;long lived&quot; means that they needed to refresh (or specifically: reload) eventually, and that reload in IE would cause an <a href="javascript:window.xpaudio.play()">audible clicking noise</a> (this was actually a feature of XP&#39;s audio suite). Imagine for a moment, that clicking, coming from seemingly nowhere, on a regular basis when you&#39;re chatting online with your friends. Annoying!</p>
<audio id="xpaudio" controls style="width: 100%;" src="/downloads/clicking.wav"></audio>

<p>The solution is amazing (or certainly to me) and the epitome of the web: a hack upon hack upon hack.</p>
<p><a href="http://infrequently.org/2006/02/what-else-is-burried-down-in-the-depths-of-googles-amazing-javascript/">The solution</a> would be to create an ActiveX htmlfile object, drop the document with an iframe inside that and the clicking would be suppressed.</p>
<p>And so a stable server push technology emerged.</p>
<hr>
<p>Comet was coined by <a href="http://infrequently.org">Alex Russell</a> (of Dojo fame, and now simply known as The&nbsp;Oracle™ at Google/he works on Blink) <a href="http://infrequently.org/2006/03/comet-low-latency-data-for-the-browser/">defined</a> as a method to push data from the server to the client (the browser).</p>
<p>Comet is not a specific technology, but more of an abstracted process. The implementation varied, and frankly at the time, was better suited to system engineers rather than your cowboy developer...like me.</p>
<p>Comet <em>could</em> involve any mix of iframes (of course!), long polling, XHR, long running script tags, and so on. To add to complexity, there were oddly named protocols like the Bayeux protocol and BOSH.</p>
<p>All things that provided barrier to entry, but real time, rightly, was hard. Real time appeared more and more across the web.</p>
<hr>
<p><strong>The real hurdle is that there&#39;s <em>two</em> parts to real time: client <em>and</em> the server.</strong></p>
<hr>
<p>The usual set up for a server in the mid-2000s was to use a <a href="http://en.wikipedia.org/wiki/LAMP_(software_bundle">LAMP stack</a>. Apache being the main sticking point.</p>
<p>Apache is designed (out of the box) to run and spawn a number of processes to deal with concurrent requests.</p>
<p>So if you have 5 apache processes waiting to deal with web requests, and you have 6 requests, the 6th user will have to wait until there&#39;s a free process before apache can respond.</p>
<p>This is usually find when you&#39;re deal with a request/response situation, apache is fast for that. But when you&#39;re keeping connections open to allow a server to <em>push</em> a message to the client, you saturate the available apache processes.</p>
<p>What does this mean in practise? If you have 5 processes and 6 streaming <em>requests</em>, the 6th <em>will never</em> receive a response. And to that user, the site is hanging indefinitely.</p>
<p>The solution to the server issue is evented server. If I recall correctly, this would be: Twisted for Python, Jakarta for Java, Juggernaut for Ruby, etc. But they were non-trivial to set up.</p>
<p>Come 2009 and Ryan Dahl.</p>
<h2>Node is introduced</h2>
<p><img src="/images/ryan-node.jpg" alt="Ryan introduces Node at jsconf"></p>
<p>At the first jsconf.eu, Ryan Dahl, introduced <a href="http://lanyrd.com/2009/jsconfeu/skpz/">node.js: evented IO for V8</a>.</p>
<p>The talk starts quite technical and detailed, but Ryan started to draw similarities with what he was doing with node.js with the DOM.</p>
<p>Although node.js has nothing to do with the DOM, the way that the event loop works is very similar to the way a browser will work.</p>
<h3>The event loop</h3>
<p>This is what an event loop <em>could</em> look like:</p>
<pre><code class="language-lua">function main
  initialize()
  while message != quit
    message := get_next_message()
    process_message(message)
  end while
end function</code></pre>
<p>In a browser, the <code>get_next_message</code> could be the user clicking the mouse, or an XHR request completing, or a render, or some JavaScript being run. The point being is that the loop waits for a task, then processes that task.</p>
<p>This is where node.js makes concurrent requests (i.e. holding 100s if not 1000s of open connections to clients) easy.</p>
<h3>helloworld.js of streaming servers</h3>
<p>As Ryan demoed in his talk 5 years ago, the code following is the simple proof that comet servers are incredibly simple with Node. The key with the server side is being able to hang inbound requests <em>whilst</em> also getting on with other work, like accepting more inbound requests.</p>
<pre><code class="language-js">var http = require(&#39;http&#39;);

var server = http.createServer(function (req, res) {
  res.writeHead(200, { &#39;content-type&#39;: &#39;text/html&#39; });
  res.write(&#39;&lt;script&gt;console.log(&quot;this is the start of the stream...&quot;)&lt;/script&gt;&#39;);

  var timer = setInterval(function () {
    // if the connection has closed, and we can&#39;t write anymore
    if (!res.connection || !res.connection.writable) {
      // then clear this interval, and *attempt* to end the response
      clearInterval(timer);
      res.end();
    } else {
      // otherwise, keep sending a script with logging
      res.write(&#39;&lt;script&gt;console.log(&quot;and now more messages...&quot;)&lt;/script&gt;&#39;);
    }
  }, 2000);
});

server.listen(8080);</code></pre>
<p>This code is saved to <code>server.js</code> and run using <code>node server.js</code> and now I can visit <code>localhost:8080</code> on my machine, and it should start logging, in 2 second increments &quot;and now more messages...&quot; (<a href="http://lit-thicket-2959.herokuapp.com/">live demo version that writes to the DOM</a>).</p>
<p>A comet server has a bit more to it, but with this simple few lines of code we can create as many persistent connection as we like and our server will continue to accept requests.</p>
<p>During the timeout, the server isn&#39;t &quot;sleeping&quot;, it&#39;s <em>waiting</em> for the next event, be it the time it to fire, or for another request to come in.</p>
<p>Equally we can easily give the server <em>more</em> things to do with the single event loop. It could be collecting live prices from a server, or making APIs calls, or have its own scheduling task all inside the single program <em>because</em> of the way node.js is architectured.</p>
<p>What&#39;s particularly elegant about node.js today, is that it&#39;s incredibly simple to install, has first class support across all three platforms (windows, linux and mac) and is extremely well documented and supported by the community.</p>
<h2>Codifying into standards</h2>
<p>As time passed, using Flash and various hacks to achieve real time eventually landed into the standards, typically under the umbrella term of HTML5.</p>
<p>That&#39;s to say, today we have <em>three</em> native client side solutions to communicating with the server:</p>
<ol>
<li>Ajax &amp; <a href="http://caniuse.com/#search=xhr2">XHR2</a>. Well known. Well loved. Well understood. The XHR2 spec takes the API further and gives us much more functionality.</li>
<li><a href="http://caniuse.com/#search=eventsource">EventSource</a>. Push based server <em>events</em>, that automatically reconnect when the connection is dropped.</li>
<li><a href="http://caniuse.com/#search=websockets">WebSockets</a>. Bi-directional, persistent sockets, that can be made across origin.</li>
</ol>
<p><em>Side note: that there is also WebRTC, which is a real-time standard in browsers today, but it&#39;s for peer-to-peer (in general), rather than with servers.</em></p>
<p>These standards are good because: all browsers implementing new features will implement these features in an interoperable way. With the exception of EventSource, all these are supported by IE10 and all other browsers (and EventSource has excellent support through <a href="http://html5please.com/#eventsource">polyfills</a>).</p>
<h2>So, what&#39;s next?</h2>
<p>Now we live in a world where both the client side <em>and</em> server side has been solved and is simple to work with, what can we actually do?</p>
<p>Here&#39;s a few examples of where I&#39;ve used node.js for real time:</p>
<ul>
<li>Live reload remote devices with user generated content (in JS Bin)</li>
<li>Codecasting - like screencasting, but with HTML, CSS &amp; JavaScript</li>
<li>Remote console injection - for running a desktop console against any mobile device (like old Android or Windows phone)</li>
<li>Proxy sensor events - streaming the accelerometer from a mobile device to desktop for testing</li>
<li>User discovery - for a two player game waiting for each other to join the session (like two users joining a chat room)</li>
<li>Push notification to browser for both progress events and when a long task has completed</li>
</ul>
<p>A lot of this is made very easy with existing node modules developed by the node community, and stress tested by everyone else.</p>
<h2>Core npm modules</h2>
<p>As I&#39;m sure many of you know, the node module repository is rife with libraries to do just about <a href="https://www.npmjs.org/package/true">everything</a>. The libraries that handle real time communication have been baked, and run through the mill pretty hard and there&#39;s lot of good choice nowadays.</p>
<p>What&#39;s particularly useful about many of these libraries is that they provide both sides of the infrastructure required to achieve real time, and usually require very little to get started.</p>
<p>The two libraries that I would encourage you to gravitate towards are <a href="http://socket.io">Socket.IO</a> (v1.x) and <a href="http://primus.io">Primus</a>.</p>
<h3>Socket abstraction</h3>
<p>Normally I prefer to be quite close to the metal, and I generally code directly with the native APIs, but in this case, both libraries give me an abstraction layer that&#39;s <em>built upon</em>. This means if I want to multiplex or have specific events emitting on a socket, it&#39;s easy as it either comes with the library (in Socket.IO&#39;s case) or can be added via middleware (for Primus).</p>
<p>The benefits of each, as I seem them are:</p>
<ul>
<li>Socket.IO: will test and degrade down to the best technology to sustain a persistent connection</li>
<li>Primus: provides a common low level interface to communicate with socket libraries and to &quot;prevent module lock-in&quot;, but of specific interest is the middleware selection</li>
</ul>
<p>For my examples, I&#39;m using Primus with the <code>websocket</code> transformer.</p>
<h2>Primus</h2>
<p>Primus used both on the server side and client side. I&#39;m using express for my examples, so we bind Primus to the express http server:</p>
<pre><code class="language-js">// setup express
var express = require(&#39;express&#39;);
var app = express();
var Primus = require(&#39;primus&#39;);

// configure express
app.use(express.static(&#39;.&#39;));
var server = require(&#39;http&#39;).createServer(app);

// start the web server
server.listen(process.env.PORT || 8000);

// now instantiate primus with our express server
var primus = new Primus(server, {
  transformer: &#39;websockets&#39;
});

// add the emit middleware letting me define my own event types
primus.use(&#39;emit&#39;, require(&#39;primus-emit&#39;));

// when we get a connection...
primus.on(&#39;connection&#39;, function (spark) {
  // the inbound socket is referred to as a &quot;spark&quot;

  // respond to ping events with a pong
  spark.on(&#39;ping&#39;, function () {
    spark.emit(&#39;pong&#39;);
  });
});</code></pre>
<p>The client side is simple and small, and also has the ability to emit (rather than <em>just</em> <code>primus.on(&#39;data&#39;, fn)</code> and <code>primus.write(data)</code>) because the server includes the <a href="https://github.com/primus/emit">emit</a> middleware:</p>
<pre><code class="language-html">&lt;!-- magic script provided by primus, note that --&gt;
&lt;!-- this can saved and served as a static file --&gt;
&lt;script src=&quot;/primus/primus.js&quot;&gt;&lt;/script&gt;
&lt;script&gt;
var primus = Primus.connect(&#39;/&#39;);

primus.on(&#39;pong&#39;, function () {
  alert(&#39;Pong received loud and clear&#39;);
});

primus.emit(&#39;ping&#39;);
&lt;/script&gt;</code></pre>
<p><a href="http://sheltered-wave-6638.herokuapp.com/">Here&#39;s a live demo</a> (for what it&#39;s worth!). That&#39;s really all there is to it. The source for my <a href="https://github.com/remy/face-hit-game">face-tap game is on github</a> and can be seen on <a href="http://game.rem.io">game.rem.io</a> and be sure to try it whilst you have the <a href="http://game.rem.io/scores">scoreboard</a> open.</p>
<p>The game uses Primus to communicate, but also includes a broadcast function to all except &quot;me&quot;:</p>
<pre><code class="language-js">function broadcast(event, data, source) {
  primus.forEach(function (spark) {
    if (spark.id !== source.id) {
      spark.emit(event, data);
    }
  });
}</code></pre>
<h2>Scaling</h2>
<p>This is a problem on both the server side <em>and</em> the client. The server side you want to use the same techniques you&#39;d use for regular web traffic: <a href="http://www.haproxy.org/">HAProxy</a>, <a href="https://github.com/nodejitsu/node-http-proxy">node-http-proxy</a>, nginx, etc. <a href="http://tech.blog.box.com/2014/06/node-js-high-availability-at-box/">Nicholas Zakas has an excellent article</a> on scaling with HAProxy.</p>
<h3>Client side</h3>
<p>On the client, the issue is saturating the concurrent connections you can have per origin. The <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8">HTTP 1.1 spec</a> states the following for persistent connections:</p>
<blockquote>
<p>Clients that use persistent connections SHOULD limit the number of simultaneous connections that they maintain to a given server. A single-user client SHOULD NOT maintain more than 2 connections with any server or proxy. These guidelines are intended to improve HTTP response times and avoid congestion.</p>
</blockquote>
<p>However we know that <a href="http://www.chromium.org/developers/design-documents/network-stack#TOC-Connection-Management">Chrome has increased</a> this default from 2 to 6 per origin. It doesn&#39;t matter what the per browser implementation issue is because they&#39;re all <em>quite</em> low.</p>
<p>One solution that I know of is (and I believe Facebook also do this) is to generate a random origin address (usually a CNAME) so your socket is connecting to <code>ws://e01938e4.example.com</code> and this is aliased back on to your socket server. This way you constantly generate a new origin for the socket to connect through and you don&#39;t hit the early limit of 6 (or so) concurrent connections.</p>
<p>If I was using Heroku to scale, I&#39;d add the domain <code>*.example.com</code> to the list of domains in the settings panel for the app.</p>
<p>Now <code>anything.example.com</code> will land on my Heroku app and I can bypass the browser&#39;s limit on persistent connections by origin.</p>
<h3>Server side</h3>
<p>Once you scale horizontally with a proxy - or even just drag a Heroku dyno to 11 - you&#39;ll be asking yourself how does a socket connected to <code>server A</code> talk to a socket connected to <code>server B</code>?</p>
<p>The solution I&#39;ve been exploring is using Primus&#39; middleware combo of <a href="https://github.com/primus/metroplex">metroplex</a> and <a href="https://github.com/primus/omega-supreme/">omega-supreme</a> (yes, there&#39;s a Transformer theme!).</p>
<p>Metroplex registers your server in a Redis database (version 2.6 or above is required - brew seemed to ship 2.4) upon startup (which <em>should</em> auto unregister after 5 minutes of idle). That way you can query redis to ask what servers are also active:</p>
<pre><code class="language-js">// I&#39;m passing in a redis instance so that all my
// instances of this server connect to the _same_
// redis database.
var primus = new Primus(server, {
  transformer: &#39;websockets&#39;,
  redis: redis,
});

// add the Primus middleware (after instantiation)
primus.use(&#39;metroplex&#39;, require(&#39;metroplex&#39;));
primus.use(&#39;omega-supreme&#39;, require(&#39;omega-supreme&#39;));
primus.use(&#39;emit&#39;, require(&#39;primus-emit&#39;));

// now I can query the registered servers
primus.metroplex.servers(function (err, servers) {
  console.log(&#39;other servers: %d&#39;, servers.length, servers);
});</code></pre>
<p>Note that the address for the server is the same address as the webserver that your Primus instance is bound to.</p>
<p>Then with omega-supreme, you can forward messages to known servers. So if <code>server A</code> knows that <code>server B</code> is active, it can forward broadcast messages to <code>server B</code>:</p>
<pre><code>primus.forward(server, data, function (error, data) {
  // data contains the number of sparks that got the message
});</code></pre>
<p>The above example, <code>server</code> would be the address of <code>server B</code>. Now if we upgrade the <code>broadcast</code> function from above, it would look like this:</p>
<pre><code>function broadcast(event, data, source) {
  // query which servers are registered to our redis db
  primus.metroplex.servers(function (err, servers) {
    servers.forEach(function (server) {
      primus.forward(server, {
        emit: [event, data]
      }, noop);
    });
  });

  // note that the primus forward will handle this for us
  primus.forEach(function (spark) {
    if (spark.id !== source.id) {
      spark.emit(event, data);
    }
  });
}</code></pre>
<p>Note that for omega-supreme to support the <code>emit</code> method for named events, instead of passing in <code>data</code> as the second argument to <code>primus.forward</code>, you pass in an object that simply contains <code>emit: [event, data]</code>. This will then fire the named events as I&#39;m using them in my code.</p>
<p>This is effectively what a client sending a broadcast would look like if Redis was backing the Primus setup:</p>
<p><img src="/images/primus-scale.svg" alt="Primus with omega-supreme and metroplex"></p>
<h2>Long-latency real time feedback</h2>
<p>One aspect that particularly interests me is long running requests. For example, when I created <a href="http://5minfork.com">5minfork</a> (a site that clones a github repo and hosts it for 5 minutes), there&#39;s a point when the user requests to clone a git repo and there&#39;s a potential latency period while the server clones.</p>
<p>This period length is unknown (i.e. we could be cloning a large project which takes time), but we do know that it&#39;s <em>not instant</em>. So how do we communicate to the user that work is in progress and <em>most importantly</em> tell the user that the work is done and they can proceed?</p>
<p>Easily with node.js because the server can kick off a background process, and whilst it&#39;s cloning, instead of waiting, the node server continues to accept web requests. This way we can serve a holding page to indicate that we&#39;re actively working on the cloning process.</p>
<p>I&#39;ve replicated this process in the <a href="http://long-latency.rem.io/random">long latency demo</a> (<a href="https://github.com/remy/long-poll-status">source also available</a>)</p>
<p>This consists of:</p>
<ol>
<li>A <code>GET</code> request handler to start the (fake) long latency process. The URL is given a unique identifier and we set a flag for that identifier to say it&#39;s in progress.</li>
<li>The server responds with a holding page that will open a poll request to the same URL we <code>GET</code> in step 1 (equally this could be a long poll or a Web Socket or something to keep checking on the status).</li>
<li>The poll eventually gets some status that the server is done performing it&#39;s task, and trigger a refresh of the same page (though this could be handled in all manners of ways).</li>
</ol>
<p>Since node is very good at asynchronous type code (though it&#39;s not better than others, it&#39;s just a much more natural workflow), it makes kicking off a background task and responding immediately to the &quot;are we there yet&quot; requests, however they&#39;re made, very very simple.</p>
<h2>To wrap up</h2>
<p>It is exceptionally easy to add real-time to your project using Node.js. Node on a single CPU without any optimisation can work out very well for most small to medium sized projects.</p>
<p>We&#39;ve leaped so far ahead in the last 10 years, that it&#39;s insane how simple it is to add real-time via projects like Socket.io and Primus.</p>
<p>Don&#39;t be afraid to try it out. Even if it&#39;s for your own side/tinker project that you whip up and post on heroku (as are all these demos). It&#39;s too easy, and it&#39;s too important for today&#39;s user expectations not to!</p>
]]></content:encoded></item><item><title>Motivation</title><guid isPermaLink="false">motivation</guid><link>http://remysharp.com/2014/10/27/motivation</link><pubDate>Mon, 27 Oct 2014 10:30:00 +0000</pubDate><description><![CDATA[The world ain&#39;t all sunshine and rainbows. It&#39;s a very mean and nasty place and I don&#39;t care how tough you are it will beat you to your knees and keep you there permanently if you let it. You, me, or nobody is gonna hit as hard as life. But it ain&#39;t about how hard ya hit. It&#39;s about how hard you can get it and keep moving forward. How much you can take and keep moving forward.

Behind the screen, behind the internet, I&#39;m generally a bit of a depressive chap. I have been for many, many years. Going back to early childhood. I&#39;ve not talked about it online before, and I&#39;m not sure how much I will in the future.]]></description><content:encoded><![CDATA[
<blockquote>
<p>The world ain&#39;t all sunshine and rainbows. It&#39;s a very mean and nasty place and I don&#39;t care how tough you are it will beat you to your knees and keep you there permanently if you let it. You, me, or nobody is gonna hit as hard as life. But it ain&#39;t about how hard ya hit. It&#39;s about how hard you can get it and keep moving forward. How much you can take and keep moving forward.</p>
</blockquote>
<p>Behind the screen, behind the internet, I&#39;m generally a bit of a depressive chap. I have been for many, many years. Going back to early childhood. I&#39;ve not talked about it online before, and I&#39;m not sure how much I will in the future.</p>
<p>When I realise that I&#39;m in a slump of depression, it&#39;s like a weight on my back and around my neck. I imagine Superman with a cloak of Kryptonite.</p>
<p>It&#39;s shit. It&#39;s <em>really</em> shit. I know how I want to feel, I want to feel happy, grateful, I want to laugh and feel loved, yet I can&#39;t get there. It&#39;s shit that I can&#39;t.</p>
<p>I can see myself wanting to be alone, retreating and wanting to hide from everything.</p>
<p>That&#39;s when I need motivation. <em>This is new for me</em>. I&#39;ve found motivation to move forward. To take what my depression has to give and tell myself (out loud) over and over that I will make it out of this feeling.</p>
<p>I&#39;ve recently found motivation from a few very specific things I&#39;ve read and heard.</p>
<p>The first was the quote from the start of this post. I heard <em>two</em> things in this speech (from Rocky Balboa no less):</p>
<ol>
<li>How my children are the world to me, and I&#39;m there to help them get through the world and I have to be a strong model for them.</li>
<li>Thanks to Julie (my wife), realising that this speech applies to me and my wife. Losing our daughter to stillbirth, we managed, somehow, to survive, and to stay strong.</li>
</ol>
<p>The second I came across after Robin Williams on 11-August 2014 took his own life:</p>
<blockquote>
<p><strong>Depression lies</strong>.</p>
</blockquote>
<p>I&#39;d never thought of it like that, but it does. I can be doing nothing, and a thought just pops into my head like: &quot;...the reason you were hated at collage was...&quot;. But if I tell myself &quot;depression lies&quot;, I realise that thought is utter bullshit. I&#39;ve no idea what motivates my brain to produce real thoughts like that, but if I tell myself, out loud, &quot;depression lies&quot;, I&#39;m able to take a breath and brush the nastiness off.</p>
<p>I read about this first on Will Wheaton&#39;s blog: <a href="http://wilwheaton.net/2012/09/depression-lies/">depression lies</a> and I found <a href="http://wilwheaton.net/2014/05/you-stand-at-the-edge/">this post useful too</a>.</p>
<p>Finally, I watched <a href="https://www.youtube.com/watch?v=gkjW9PZBRfk">Emma Watson&#39;s address to the UN</a>. It fired something up inside of me. Something that I identified with and believe in. I intend to show my son and daughter the video when they&#39;re old enough to pay attention (currently 3 years and 5 months respectively, so they&#39;re a way off).</p>
<p>I can&#39;t quite articulate what it is that makes me motivated to move forward in Watson&#39;s address, but I emplore you watch the video. It&#39;s 13 minutes. Incredibly inspiring and something I think all young and old should watch, boys in particular.</p>
<hr>
<p>For me, I need something to reach into my slump and lend it&#39;s hand to pull me up. These three things are helping me do that for me right now. I love my family so much, and I want them to feel loved by me.</p>
<hr>
<p>This post is first and foremost for me. When I feel shit again, I&#39;ll find this post again, read it, and remember that I <em>can</em> stand tall, and say: depression lies. Fuck you, depression.</p>
<p><small>Reposted from <a href="https://the-pastry-box-project.net/remy-sharp/2014-october-5">The Pastry Box Project</a></small></p>
]]></content:encoded></item><item><title>Adding an (SHA256 signed) SSL certificate</title><guid isPermaLink="false">how-to-add-ssl</guid><link>http://remysharp.com/2014/10/17/how-to-add-ssl</link><pubDate>Fri, 17 Oct 2014 9:00:00 +0000</pubDate><description><![CDATA[I&#39;ve had to update the SSL certificate quite a few times on jsbin.com in the last 6 months, and I keep a cheatsheet of SSL steps on my machine. So it&#39;s about time I publish it somewhere that I can google too!]]></description><content:encoded><![CDATA[
<p>I&#39;ve had to update the SSL certificate quite a few times on <a href="http://jsbin.com">jsbin.com</a> in the last 6 months, and I keep a cheatsheet of SSL steps on my machine. So it&#39;s about time I publish it somewhere that I can <em>google</em> too!</p>
<p>This walkthrough explains how to add an SSL certificate to your server. This is based on using a linux based machine (in my case Ubuntu) and nginx as the server.</p>
<p>I registered my SSL certificate via <a href="https://namecheap.com">namecheap</a> from RapidSSL which is actually a shell for GeoTrust.</p>
<p>If you&#39;re reissuing a certificate to upgrade to SHA256 (from SHA-1) (because <a href="https://konklone.com/post/why-google-is-hurrying-the-web-to-kill-sha-1">SHA-1 is being ditched</a>) from RapidSSL <strong>you must</strong> reissue directly from them. See <a href="https://github.com/konklone/shaaaaaaaaaaaaa/issues/24#issuecomment-54021941">this comment</a> for full details.</p>
<p>Assuming my site is example.com, I&#39;m using <code>example</code> as the main filename.</p>
<pre><code class="language-nohighlight">openssl genrsa -aes256 -out example-encrypted.key 2048
openssl rsa -in example-encrypted.key -out example-decrypted.key
openssl req -new -sha256 -key example-decrypted.key -out example.csr</code></pre>
<p>The last command will generate the CSR which will go off to your SSL issuer. I have this a cheatsheet for the prompts (if you&#39;re based in the UK, since <code>Locality</code> might not mean much):</p>
<ul>
<li>Country name: <code>GB</code>, a country code, not name</li>
<li>State: <code>East Sussex</code>, county if you&#39;re in the UK</li>
<li>Locality: <code>Brighton</code>, your city</li>
<li>Organisation: <code>My Company Ltd</code></li>
<li>Org unit: leave empty</li>
<li>Common name: <code>www.example.com</code>, the full domain for the cert</li>
<li>Leave the rest blank (email, challenge password &amp; company name)</li>
</ul>
<p><strong>Note:</strong> if you have a wildcard certificate, then the common name is <code>*.example.com</code>.</p>
<p>Send <code>example.csr</code> contents to reissued SSL cert, and agree to all the emails.</p>
<p>You should get an email from the SSL issue with the certificate. Save the contents of &#39;certificate&#39; in <code>example.crt</code>.</p>
<p>Now get the intermediate certificate (I&#39;m using <a href="https://knowledge.rapidssl.com/support/ssl-certificate-support/index?page=content&amp;actp=CROSSLINK&amp;id=SO26459">RapidSSL&#39;s SHA256 cert</a>) and combine into a single bundled file - note that the order is important:</p>
<pre><code class="language-nohighlight">cat example.crt intermediate.crt &gt; bundle.crt</code></pre>
<hr>
<p><em>RapidSSL specific note</em>: I found that the GeoTrust certificate (part of the intermediate certificate that I downloaded above) was still SHA-1 signed. So I dropped it, only bundling my own certificate and the rapidSSL certificate (so less certificates) and now I get the green lock from Chrome Canary. Note: I&#39;m not <em>100%</em> if this is okay, but it does seem valid.</p>
<hr>
<p>Finally, make sure nginx (in my case) is using the bundle and the key used to generate the csr:</p>
<pre><code class="language-conf">ssl                  on;
ssl_certificate      /WWW/example.com/certs/bundle.crt;
ssl_certificate_key  /WWW/example.com/certs/example-decrypted.key;</code></pre>
<p>Then restart nginx:</p>
<pre><code class="language-nohighlight">nginx -s reload</code></pre>
<h2>References &amp; tools:</h2>
<ul>
<li><a href="https://shaaaaaaaaaaaaa.com/">shaaaaaaaaaaaaa</a> (for checking SHA-1)</li>
<li><a href="https://www.ssllabs.com/ssltest/analyze.html">SSL labs</a> (for deep SSL analysis)</li>
<li><a href="https://www.sslshopper.com/article-most-common-openssl-commands.html">common openssl commands</a></li>
</ul>
]]></content:encoded></item><item><title>Element focus utility</title><guid isPermaLink="false">focus-dev-util</guid><link>http://remysharp.com/2014/10/14/focus-dev-util</link><pubDate>Tue, 14 Oct 2014 13:30:00 +0000</pubDate><description><![CDATA[I&#39;ve recently been looking at retrofitting keyboard navigation support to JS Bin, but I was immediately struck by the totally lack of visibility on what was in focus.]]></description><content:encoded><![CDATA[
<p>I&#39;ve recently been looking at retrofitting keyboard navigation support to JS Bin, but I was immediately struck by the totally lack of visibility on <em>what</em> was in focus.</p>
<p>Sure, this is a short-coming of the original design and bad choises I had made with JS Bin&#39;s code base. Perhaps you can see from the animation below, when the <code>body</code> is in focus, tabbing is focusing <em>something</em> but until I actually tab to the &quot;HTML&quot; panel title, there&#39;s no visual feedback as to <em>what</em> I should be fixing:</p>
<p><img src="/images/tab-focus-clueless.gif" alt="Tab focusing is clueless"></p>
<p>If you can see it, the browser&#39;s status bar tells me that I&#39;m moving focus, but it&#39;s near impossible to work out which element I&#39;m working with.</p>
<p>So I built a mini utility to visualise what&#39;s happening. Now with that utility:</p>
<p><img src="/images/tab-visibility.gif" alt="Tabbing visible"></p>
<h2>Installation</h2>
<p>Either add the code directly to your project as a debug dependancy, or use it as a snippet in your devtools:</p>
<pre><code class="language-js">(function () {
  var active = document.createElement(&#39;pre&#39;);
  document.body.appendChild(active);
  active.tabindex = -1;
  with (active.style) { // warning: `with` I know what I&#39;m doing!
    position = &#39;fixed&#39;;
    padding = &#39;2px&#39;;
    bottom = right = &#39;20px&#39;;
    margin = 0;
    fontSize = 12;
    color = &#39;#fff&#39;;
    background = &#39;#aaa&#39;;
    whiteSpace = &#39;pre-wrap&#39;;
    maxWidth = &#39;95%&#39;;
  }

  var lastActive = null;
  var showActive = function () {
    var el = document.activeElement;
    var html = &#39;&#39;;
    var attrs = el.attributes;
    var i = 0;

    if (el !== lastActive &amp;&amp; el !== active) {
      for (; i &lt; attrs.length; i++) {
        html += &#39; &#39; + attrs[i].name + &#39;=&quot;&#39; + attrs[i].value + &#39;&quot;&#39;;
      }

      active.textContent = &#39;&lt;&#39; + el.nodeName.toLowerCase() + html + &#39;&gt;&#39;;
      lastActive = el;
    }

    requestAnimationFrame(showActive);
  };

  showActive();
})();</code></pre>
<p>Here&#39;s a live demo:</p>
<p><a class="jsbin-embed" href="https://jsbin.com/yibiwa/2/embed?output">JS Bin</a><script src="https://drt35l4oshkgr.cloudfront.net/js/embed.js"></script></p>
<p>So now I have visibility on <em>what</em> is being focused, I can fix various issues ranging from <code>outline</code> being removed, only including <code>:hover</code> styles and not <code>:focus</code> and applying <em>proper</em> <a href="http://oaa-accessibility.org/example/25/">menu logic</a> to menu-like objects.</p>
]]></content:encoded></item><item><title>What is a &quot;Web App&quot;?</title><guid isPermaLink="false">what-is-a-web-app</guid><link>http://remysharp.com/2014/10/06/what-is-a-web-app</link><pubDate>Mon, 06 Oct 2014 16:00:00 +0000</pubDate><description><![CDATA[In technology definitions are important. We talk in a language that&#39;s mostly made up by our own industry.
Bugs, cache, regressions, polyfills, monads, polymorphic functions, isomorphic JavaScript and a lot more language. Even when you do work in our industry, it&#39;s hard to keep up with all the language.
There there&#39;s &quot;web app&quot;. A lot of people (including myself) will refer to many web sites as apps. But why? I don&#39;t know of a good definition (&quot;good&quot; in that there&#39;s no hand-waving involved).
So here&#39;s my definition and distinction between web site and web app.]]></description><content:encoded><![CDATA[
<p>In technology definitions are important. We talk in a language that&#39;s mostly made up by our own industry.</p>
<p>Bugs, cache, regressions, polyfills, monads, polymorphic functions, isomorphic JavaScript and a lot more language. Even when you <em>do</em> work in our industry, it&#39;s hard to keep up with all the language.</p>
<p>There there&#39;s &quot;web app&quot;. A lot of people (including myself) will refer to many web sites as <em>apps</em>. But why? I don&#39;t know of a good definition (&quot;good&quot; in that there&#39;s no hand-waving involved).</p>
<p>So here&#39;s my definition and distinction between web site and web app.</p>
<h2>Web site</h2>
<p>A URL that you visit. Classic examples include a blog or a wiki. Where the content is waiting for you at the end of the URL.</p>
<p>JS Bin is a web site by this definition. You visit the URL and create content. Someone will share a bin, and you visiting this content. <strong>You go to the site</strong>.</p>
<h2>Web app</h2>
<p>A URL that you take with you. This is locally installed and data is <em>pushed to you</em>. Classic examples of this are email clients, news readers, task orientated applications. <strong>The app goes with you</strong>.</p>
<p>Importantly: you expect it to be available with or without an internet connection.</p>
<blockquote>
<p>Isn&#39;t this just a web site with offline support?</p>
</blockquote>
<p>I&#39;m still scoffing at &quot;<em>just</em>&quot;. Sure, if you want to dumb it down as such. But equally isn&#39;t an app on your screen, like Chrome or TomTom or PhotoShop, <em>just</em> some compiled code? Yes, it is, but it&#39;s actually a lot more than that.</p>
<p>The common language word we refer to compiled programs are: apps.</p>
<p>It&#39;s not that it&#39;s harder to build web apps, it&#39;s that the experience with these types of web sites are fundamentally different to a web site like Wikipedia for instance.</p>
<hr>
<p>The future of web browsers is coming, and they&#39;re giving us more and more support for offline technology, through storage (for data caching) to control over the network (through <a href="https://github.com/slightlyoff/ServiceWorker">service workers</a>).</p>
<p>If you&#39;re using progressive enhancement, then your web site can achieve both. However, I don&#39;t believe it&#39;s entirely possible to create a web app without the functionality that JavaScript provides. So there&#39;s is <em>some</em> expectation that a web app relies on JavaScript, but that&#39;s not what makes a web app.</p>
<p>Now, next time you&#39;re asked to build a web app, at least you can have a feature set that you&#39;re working towards.</p>
]]></content:encoded></item><item><title>WordPress -&gt; Ghost -&gt; Harp (part 2)</title><guid isPermaLink="false">wordpress-ghost-harp-pt2</guid><link>http://remysharp.com/2014/09/30/wordpress-ghost-harp-pt2</link><pubDate>Tue, 30 Sep 2014 9:00:00 +0000</pubDate><description><![CDATA[I wrote about moving away from WordPress to Ghost and then to Harp in part 1, this post details some of the specifics of my blog&#39;s implementation.]]></description><content:encoded><![CDATA[
<p>I wrote about moving away from WordPress to Ghost and then to Harp in <a href="/2014/09/18/wordpress-ghost-harp-pt1">part 1</a>, this post details some of the specifics of my blog&#39;s implementation.</p>
<h2>Technical overview</h2>
<p>I&#39;m using <a href="http://harpjs.com">Harp</a> which is incredibly easy to get running with, but I&#39;m also running Harp as a dependency inside my own custom node web server which allows me to add a few bells a whistles to my implementation.</p>
<ul>
<li><a href="#custom-url-rewriting">Custom URL rewriting</a></li>
<li><a href="#static-caching">Static caching</a></li>
<li><a href="#use-of-special-helpers-inside-harp">Use of special helpers inside Harp, such as moment.js</a></li>
<li><a href="#list-of-recently-modified-posts">List of recently modified posts</a></li>
<li><a href="#archive--tag-pages-without-the-repetition-of-files">Archive &amp; tag pages without the repetition of files</a></li>
<li><a href="#makefile-based-release-process">Makefile based release process</a></li>
</ul>
<h2>Custom URL rewriting</h2>
<p>Since I was porting an existing blog, I wanted to ensure that the URLs didn&#39;t change. This meant supported my old <code>/year/month/day/title</code> format. Which over the years I dislike, but when I moved to Harp, I decided to drop the date from the body of my posts and allow the URL to speak for that metadata.</p>
<p>I <em>also</em> wanted to host my old downloads and demos on Amazon S3, but the URLs from old posts would be relative to my blog, so I needed to rewrite these.</p>
<p>I forked <a href="https://www.npmjs.org/package/router">router@npm</a> to create <a href="https://www.npmjs.org/package/router-stupid">router-stupid@npm</a> - which is essentially the same, slightly cut down, but importantly: if you modify the <code>req.url</code> in a route handler, that would affect the subsequent matched routes.</p>
<p>Redirecting is simple:</p>
<pre><code class="language-js">/* redirect to s3 hosted urls */
route.all(&#39;/demo/{filename}&#39;, function (req, res, next) {
  res.writeHead(302, { &#39;location&#39;: &#39;http://download.remysharp.com/&#39; + req.params.filename });
  res.end();
});</code></pre>
<p>Supporting my date base URL format was trickier. The actual file lives in <code>/blog/&lt;title&gt;</code> so when the URL hits my static server, it needs to be in that form. So supporting date base URL requires:</p>
<ol>
<li>The URL format is correct</li>
<li>The title of the post actually finds a post</li>
<li>The date in the URL matches the date for the post</li>
</ol>
<pre><code class="language-js">/* main url handler: /{year}/{month}/{day}/{post} */
route.all(/^\/([0-9]{4})\/([0-9]{1,2})\/([0-9]{1,2})\/([a-z0-9\-].*?)(\/)?$/, function (req, res, next) {
  var params = req.params;

  // the title slug of the url
  var post = blogs[params[4]];

  // make sure we have a real post before even proceeding
  if (post &amp;&amp; post.date) {
    // test if the date matches

    // post.date is a timestamp, so splitting gets us the date
    var date = moment(post.date.split(&#39; &#39;)[0]);

    var requestDate = params.slice(1, 4).join(&#39;-&#39;);

    // compare the date of post _in the same format_ as requestDate
    if (date.format(&#39;YYYY-MM-DD&#39;) !== requestDate) {
      // if it&#39;s not good, move on - will likely result in a 404
      return next();
    }

    // if there&#39;s a trailing slash, remove it and redirect
    if (params[5] === &#39;/&#39;) {
      res.writeHead(302, { &#39;location&#39;: req.url.replace(/(.)\/$/, &#39;$1&#39;)});
      res.end();
      return;
    }

    // this now allows Harp to pick up the correct post
    req.url = &#39;/blog/&#39; + params[4];
  }

  // then let the rest of the router do it&#39;s work
  next();
});</code></pre>
<h2>Static caching</h2>
<p>Having used Harp in previous projects (<a href="https://github.com/jsbin/learn">JS Bin&#39;s documentation</a>, <a href="https://github.com/leftlogic/fullfrontalconf2014/">our event site</a> and <a href="https://github.com/leftlogic/leftlogic">my business site</a>) and have created <a href="https://npmjs.org/package/harp-static">harp-static@npm</a> which uses <a href="https://npmjs.org/package/st">st@npm</a> to cache and serve static files.</p>
<p>So in my custom server, I point all routes down to the <code>st</code> served content. I also support hitting the URLs <em>without</em> <code>.html</code> at the end, again, to keep my old URLs working. I&#39;d recommend checking out the <a href="https://github.com/remy/harp-static">harp-static source</a> if this interests you.</p>
<h2>Use of special helpers inside Harp</h2>
<p>At present, if you want to use a library inside Harp, like <a href="http://momentjs.com">moment.js</a>, the work around for this is to create a <code>.jade</code> file with the source of moment.js (in this case) as script. Essentially the minified one line file prefixed with a <code>-</code> character.</p>
<p>Then include the library in a common file, like the layout, and you have the helper available:</p>
<pre><code class="language-jade">!- load the moment.js library for server side access
!= partial(&#39;/js/moment&#39;)</code></pre>
<p>Except this would break during compilation to static files. I&#39;m certain it&#39;s to do with my custom serving process, but the path would somehow be wrong (so the library wouldn&#39;t load and further down my code there would be exceptions in Jade about the library not existing).</p>
<p>The <em>smart</em> way around this is to expose a global from <em>outside of Harp</em>. So in my <code>server.js</code> (that does all the routing, etc) I <code>require</code> in moment.js and then I <a href="https://github.com/remy/remysharp.com/blob/master/server.js#L26">expose it globally</a>:</p>
<pre><code class="language-js">// this line, although dirty, ensures that Harp templates
// have access to moment - which given the whole partial
// import hack doesn&#39;t work consistently across dynamic vs
// compiled, this is the cleanest solution.
global.moment = moment;</code></pre>
<p>Very simple, but now any Harp rendered file has access to moment.js. I use the same technique to expose the recently modified posts for listing on the homepage.</p>
<h2>List of recently modified posts</h2>
<p>The best way to get a list of all the post from <em>outside</em> of Harp (i.e. when you&#39;re requiring Harp as a dependency), is to simply load the <code>_data.json</code> file. It felt wrong initially, but it&#39;s perfect:</p>
<pre><code class="language-js">var blogs = require(&#39;./public/blog/_data.json&#39;);
var slugs = Object.keys(blogs);</code></pre>
<p>Now I have an object lookup by slug to the actual blog posts <em>and</em> I have an array of the slugs.</p>
<p>From this, I was able to <code>fs.stat</code> all the blog posts and sort to return the 3 most recently modified and then using the previous trick, expose it globally so it&#39;s included on my homepage (where <code>recent</code> is the global exposed in <code>server.js</code>):</p>
<pre><code class="language-jade">each post in recent
  li
    a(href=&quot;#{ public.blog._data[post.slug].relative }&quot;) #{ public.blog._data[post.slug].title }
    small &amp;nbsp;updated #{ moment(post.date).fromNow() }</code></pre>
<h2>Archive &amp; tag pages without the repetition of files</h2>
<p>There&#39;s two parts to this section. Firstly there&#39;s the support for individual years or tags without duplication of (too much) code. Secondly is the Jade code that runs the archive listing.</p>
<h3>Reducing duplication of code</h3>
<p>I <em>could</em> have a directory for each year there are blog posts (which I do have now) and each could contain the archive listing code. The problem (obviously) is duplication of code. You fix it one place, and (in my case, since I have 2006-2014) you have 8 files to update.</p>
<p>Instead, a single file <code>index.jade</code> sits in tagged folder (and similarly with year folders) which contains:</p>
<pre><code class="language-jade">!= partial(&#39;../../_partials/tag&#39;)</code></pre>
<p>So we load a single partial. The <code>tag.jade</code> file simply reads the path of the request, and uses the last part as a filter against all the posts:</p>
<pre><code class="language-jade">tag = filter === undefined ? current.path.slice(-2, -1)[0] : filter;
posts = partial(&#39;posts&#39;, { filter: function (post) { return post.tags.indexOf(tag) !== -1 } })
.post
  h1.title Tagged with &quot;#{ tag }&quot;
  .post-content
    ul
      while posts.length
        post = posts.shift()
        if post.date
          li
            a(href=&quot;#{ post.relative }&quot;) #{ post.title }
            small.date #{ moment(post.date).format(&#39;D-MMM YYYY&#39;)}</code></pre>
<p>Note that <code>partial(&#39;posts&#39;)</code> is a magic partial that simply returns an array of blog posts with the passed in filter applied.</p>
<p>Simple. Now if I want to add more support for tags, I just create a directory and the simple <code>index.jade</code> and it works.</p>
<h3>An archive listing</h3>
<p>A while loop that looks for a year change in the date, then works through each year, popping from the posts array looping through each post in the month.</p>
<p>It&#39;s pretty cool (I think) because it works for entire years <em>and</em> all years: <a href="https://github.com/remy/remysharp.com/blob/a198a4235634a3c7ac747ab403ac13bc49140a39/public/_partials/archive.jade">archive.jade</a></p>
<h2>Makefile based release process</h2>
<p>Disclaimer: this is a terrible use of a Makefile, it doesn&#39;t leverage <em>any</em> of the benefits of make, and honestly, it <em>could</em> be a bash script. However, I like that I can run <code>make publish</code>.</p>
<p>Taking a lead from <a href="https://andreypopp.com/posts/2013-05-16-makefile-recipes-for-node-js.html">Makefile recipes for Node.js packages</a>, my <a href="https://github.com/remy/remysharp.com/blob/master/Makefile">makefile</a> allows me to run commands like:</p>
<pre><code class="language-bash">$ make release-minor publish</code></pre>
<p>The <code>release-*</code> tasks will:</p>
<ol>
<li>Bump the package version (according to patch/minor/major)</li>
<li>Compile Harp to static files</li>
<li>Commit all changes and tag</li>
<li>Push to github</li>
</ol>
<p>The version bump has to happen first so that the version I used to cache bust in the compiled output is correct (otherwise you bump after the compilation, and then your released version is one step ahead of the version that appears in the source).</p>
<p>And that&#39;s it! Here&#39;s the full running <a href="https://github.com/remy/remysharp.com">source to remysharp.com</a> - feel free to help yourself to anything that&#39;s useful for your own blogs or sites.</p>
]]></content:encoded></item><item><title>My  Velveteen Rabbit</title><guid isPermaLink="false">my-velveteen-rabbit</guid><link>http://remysharp.com/2014/09/24/my-velveteen-rabbit</link><pubDate>Wed, 24 Sep 2014 16:30:00 +0000</pubDate><description><![CDATA[This is the Velveteen Rabbit. The same picture hangs in my house.
I&#39;ve never bought any artwork in my life previously. I&#39;ve never really &quot;got it&quot;.
I walked past the picture in a shop window most days back from the gym, and something kept reaching out to me. I&#39;d stop and just look at the picture for several minutes before continuing my journey.
One time I even passed the picture, then turned back to spend a few idle minutes contemplating what it was that I drawn to.
My wife, Julie, eventually told me if something was pulling me so strongly, I should buy it. So now it hangs in my house.
I realised quickly what it was.

We lost our daughter, Tia to stillbirth on August 31 2010. My wife, after 9 months was finally in labour, and between the hours of labour and getting to hospital, she was lost. She never came home with us.
I have no proof that she exists. There were no baby clothes, no balloons, no happy photos.
It was like she didn&#39;t exist at all, and that somehow her existence was invalid.
I struggled with this a lot. I still do at times.

But I see the picture of Velveteen Rabbit. He stands there, upright and proud. Standing against the wind, feeling it on his fur and blowing his ears back. Defiant with love. &quot;I shall exist&quot;.
In that moment, that tiny moment, the Velveteen Rabbit does exist, against all odds. He&#39;s loved, and seen.
I always think of Tia when I look at that picture. She&#39;s not here any more. She doesn&#39;t exist in my world today. But she&#39;s always with me. She has left a mark. In my heart. I think of her and miss her. Other people can&#39;t see that, but she is here, with me.
A person doesn&#39;t have to be with you for you to love them. Just remember them. And love them. And they&#39;ll live on, with you.
Reposted from The Pastry Box Project]]></description><content:encoded><![CDATA[
<p><img src="/images/spring.jpg?" alt="The Velveteen Rabbit" style="display: block; max-width: 100%; width: 40%; margin: 0 auto; margin-right: 20px; float: left;"></p>
<p>This is the Velveteen Rabbit. The same picture hangs in my house.</p>
<p>I&#39;ve never bought any artwork in my life previously. I&#39;ve never really &quot;got it&quot;.</p>
<p>I walked past the picture in a shop window most days back from the gym, and something kept reaching out to me. I&#39;d stop and just look at the picture for several minutes before continuing my journey.</p>
<p>One time I even passed the picture, then turned back to spend a few idle minutes contemplating what it was that I drawn to.</p>
<p>My wife, Julie, eventually told me if something was pulling me so strongly, I should buy it. So now it hangs in my house.</p>
<p>I realised quickly what it was.</p>
<hr>
<p>We lost our daughter, Tia to stillbirth on August 31 2010. My wife, after 9 months was finally in labour, and between the hours of labour and getting to hospital, she was lost. She never came home with us.</p>
<p>I have no proof that she exists. There were no baby clothes, no balloons, no happy photos.</p>
<p>It was like she didn&#39;t exist at all, and that somehow her existence was invalid.</p>
<p>I struggled with this a lot. I still do at times.</p>
<hr>
<p>But I see the picture of Velveteen Rabbit. He stands there, upright and proud. Standing against the wind, feeling it on his fur and blowing his ears back. Defiant with love. &quot;I <em>shall</em> exist&quot;.</p>
<p>In that moment, that tiny moment, the Velveteen Rabbit does exist, against all odds. He&#39;s loved, and seen.</p>
<p>I always think of Tia when I look at that picture. She&#39;s not here any more. She doesn&#39;t exist in my world today. But she&#39;s always with me. She <em>has</em> left a mark. In my heart. I think of her and miss her. Other people can&#39;t see that, but she <em>is</em> here, with me.</p>
<p>A person doesn&#39;t have to be with you for you to love them. Just remember them. And love them. And they&#39;ll live on, with you.</p>
<p><small>Reposted from <a href="https://the-pastry-box-project.net/remy-sharp/2014-august-26">The Pastry Box Project</a></small></p>
]]></content:encoded></item><item><title>WordPress -&gt; Ghost -&gt; Harp (part 1)</title><guid isPermaLink="false">wordpress-ghost-harp-pt1</guid><link>http://remysharp.com/2014/09/18/wordpress-ghost-harp-pt1</link><pubDate>Thu, 18 Sep 2014 12:00:00 +0000</pubDate><description><![CDATA[I&#39;ve been running my &quot;b:log&quot; on WordPress since late 2006, but today I give you the node backed blog.
This is a two part blog post, the first covering why I moved, what I tried and a few of the high level issues I ran in to. Part two will cover some of the technical detail that goes in to running my blog on the new node platform.
These posts are not intended as walkthrough on how to do it yourself, but simply sharing my experience and bumps I ran into on the way, hoping to impart some useful knowledge along the way.]]></description><content:encoded><![CDATA[
<p>I&#39;ve been running my &quot;b:log&quot; on WordPress since late <a href="/2006">2006</a>, but today I give you the node backed blog.</p>
<p>This is a two part blog post, the first covering why I moved, what I tried and a few of the high level issues I ran in to. Part two will cover some of the technical detail that goes in to running my blog on the new node platform.</p>
<p>These posts are not intended as walkthrough on how to do it yourself, but simply sharing my experience and bumps I ran into on the way, hoping to impart some useful knowledge along the way.</p>
<hr>
<p>Over the years I&#39;ve had all the injections of Viagra adverts and the like over and over and over. Whenever I want to change anything, I&#39;d tend to give up, and for a few years now, I&#39;ve really wanted the source of my blog posts available in (something like) github.</p>
<p>This post is about the move and how I run my blog now.</p>
<h2>My goals</h2>
<p>In a totally ideal world, I wanted:</p>
<ul>
<li>A fast blogging platform (not particularly for publishing, but for serving)</li>
<li>Backed by JavaScript (Node specifically) - because it&#39;s the most familiar language to me</li>
<li>Edit links for posts to go to github allowing anyone to make a suggested edit</li>
<li>Archives and tag listings</li>
<li>URLs would be customisable (because I have old URLs that I want to support)</li>
<li>Could run on a free hosting platform like Heroku</li>
<li>As a bonus, I could hack and improve the system</li>
</ul>
<p>TL;DR here&#39;s the full source of my blog as it is today, on github: <a href="github.com/remy/remysharp.com"><a href="https://github.com/remy/remysharp.com/">https://github.com/remy/remysharp.com/</a></a>.</p>
<h2>Ghost</h2>
<p>I knew that I wanted to move to a node backed platform. Ghost seemed like the best fit, and I&#39;ve had the pleasure of meeting and listening to John O&#39;Nolan and Hannah Wolfe speak about Ghost, and I complete buy into the philosophy.</p>
<p>Exporting WordPress posts (and pages) to Ghost was actually very simple (I used the developer version of Ghost locally).</p>
<p>The only bump in the road was the error messaging during the Ghost import was pretty vague. But checking the devtools console yielded the answer, a 324 from my server during the upload process. So I tweaked nginx to allow for larger files to be uploaded and bosh. Fixed.</p>
<p>The next trick was the comments - which Disqus seemed like the default that everyone moves to. Obviously nothing to do with Ghost, but this process was tricky. The best advice I can give if you&#39;re doing this and keep hitting failed imports is: validate the XML (w3c validator is just fine), and hand-fix the invalid XML.</p>
<h3>Why I didn&#39;t stick with Ghost</h3>
<p>For the record, I think Ghost is an excellent platform for most users, particularly if they&#39;re coming to blogging for the first time or wanting to shift away from WordPress.</p>
<p>However, being a developer I wanted to add a few custom tweaks, specifically I wanted an archive page, a handful of URL rewrite rules and a few of the Ghost ways of doing things weren&#39;t quite what I wanted.</p>
<p>One particular example is all my old WordPress posts had split markers in them which Ghost doesn&#39;t support. They do have support for creating excepts, but if you want HTML you can&#39;t (at time of writing) append a read more to the link.</p>
<p>I tried to contribute to the Ghost project, but I ended up going down a rabbit hole for what was effectively a tiny change (submitting a pull request to a Ghost dependency Downsize).</p>
<p>The (understandable) problem is that Hannah and the Ghost team are producing code that works in a great deal of environments and so a quick PR here and there are great, but I can understand why they&#39;re not merged in right away if at all: there&#39;s a much bigger picture to consider.</p>
<p>I thought about just forking Ghost and permanently running my own version, but there&#39;s a fairly big system to inherit when all I&#39;m doing is serving pages...which I had done with Harp.js before.</p>
<p>So I made the jump to Harp.</p>
<h3>Ghost to Harp</h3>
<p>Harp is a static site generator. I&#39;ve used it in the past for <a href="http://2014.full-frontal.org">our conference site</a> this year and for the <a href="http://jsbin.com/help">JS Bin help &amp; blog</a> so I was already familiar with it.</p>
<p>However, harp requires static markdown files, so I went about connecting to the Ghost database via sqlite3 and exporting each of these records out as a static HTML file, whilst building up the <code>_data.json</code> file required by harp to represent the metadata.</p>
<p>The code I used to convert is on github here: <a href="https://github.com/remy/ghost-harp">remy/ghost-harp</a>. <em>Disclaimer</em>: I wrote this for my own database and requirements, so this may not work for you out of the box.</p>
<p>The conversion process is pretty simple, read the sqlite database, write to files. So I ended up with a folder structure like this:</p>
<pre><code class="language-nohighlight">.
├── harp.json
└── public
    ├── _data.json
    ├── about.md
    ├── blog
    │   ├── 2007-moments.md
    │   ├── 8-questions-after-ie-pissed-the-community-off.md
    │   ├── _data.json
    │   ├── _drafts
    │   │   ├── _data.json
    │   │   ├── my-velveteen-rabbit.md
    │   │   └── why-i-prefer-mobile-web-apps-to-native-apps.md
    │   ├── a-better-twitter-search.md
    │   ├── wordpress-tagging-and-textmate.md
    │   └── youre-paying-to-speak.md
    ├── talks.md
    └── twitter.md</code></pre>
<p>Some contents are going to be in HTML, but Ghost seemed to put my HTML posts in the markdown column (and since it&#39;s valid, it doesn&#39;t really matter).</p>
<p>One significant tweak I made was to put the post title <em>into</em> the post itself. For example, if you look at the source <a href="https://github.com/remy/remysharp.com/blob/master/public/about.md">about</a> page, you&#39;ll see the title in the markdown. Ghost separates out the title and the body when you&#39;re editing, but I wanted a single markdown file.</p>
<p>The next task was to fire up harp and have it running from my newly generated <code>public</code> directory.</p>
<h2>Harp</h2>
<p>Now that all my content is in the <code>public/blog</code> directory (via my little rewrite script) harp could serve my content. Using a simple (empty) <code>harp.json</code> as the config, harp automatically knows to serve anything under <code>public</code> as the root of the site (i.e. <code>/blog/foo</code> will serve the file <code>/public/blog/foo.md</code>):</p>
<p>My specific requirements for using harp were:</p>
<ul>
<li>Serves <em>static</em> content (so I&#39;d have to compile to static .html)</li>
<li>Serves in production <em>without</em> the <code>.html</code> extension visible</li>
<li>Support rewriting of URLs, so that I could maintain my original URL structure of <code>/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/&lt;post&gt;</code> rather than pointing to <code>/blog/&lt;post&gt;</code></li>
<li>I <em>really</em> wanted an archive, since I was simplifying a lot of my blog design, and losing a <em>lot</em> of navigation</li>
</ul>
<p>In the end, I had to create my own custom <code>server.js</code> that would run a bespoke router (I did use an existing library, but I needed changes, so I forked my own copy).</p>
<p>Harp certainly made things harder than using Ghost, but I had the flexability I needed.</p>
<p>I&#39;m particularly proud of the <a href="/archive">archive</a> page, partly because I managed to write it entirely with Jade (which over the years I&#39;m slowly starting to warm to) and partly because I now have a page that lists <em>all</em> my posts since the first in 2006!</p>
<p>The version I&#39;m running today satisfies all the goals I outlined at the start of the project, and more.</p>
<p>A few bonus features I built are:</p>
<ul>
<li>I can add <code>/edit</code> to any page to quickly jump to github to edit (along with edit links being on all the posts)</li>
<li>All the old demos and uploads from my WordPress site are hosted on Amazon S3 and redirected to via my <code>server.js</code></li>
<li>My development environment is slightly different to production, such as drafts are visible and the disqus comments are removed</li>
</ul>
<p>The <em>one</em> thing I&#39;d like harp to be better at would be knowing what to regenerate. Due to this my release process involves rebuilding the entire blog site (~300 posts) and then pushing the changes to github and then heroku (where I&#39;m now hosting my blog) - though this is effectively an rsync, so it&#39;s not everything that goes up.</p>
<h2>The final product</h2>
<p>The final product and platform consists of:</p>
<ul>
<li>Statically generated content in <code>/www</code></li>
<li>Source control in github</li>
<li>Production is hosted on a single dyno on Heroku</li>
<li>Using <a href="https://dnsimple.com/r/5bc02f2ef8976f">dnsimple</a> for <code>ALIAS</code> hosting to the heroku instance (so I can serve &quot;naked&quot; domains)</li>
<li>CloudFlare fronts the production blog</li>
<li>The major and minor version are used to cachebust the CSS &amp; JavaScript, due to this, it means changes to content are a patch release and all others are minor (or major) releases</li>
<li>The release process is a bash-like makefile that does all the compiling and revisioning for me</li>
</ul>
<p>So my whole release process for this blog post is now:</p>
<pre><code class="language-bash">$ make release-patch publish</code></pre>
<p>And boom, just like that, you&#39;re reading the post!</p>
<p>In part 2, I&#39;ll explain some of the code that&#39;s used to drive my blog and some of the tricks I had to use to get harp to play exactly the way I wanted.</p>
]]></content:encoded></item></channel></rss>